{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# group validation on 160 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "\n",
    "# Import relevant scikit-learn modules\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read .csv format data\n",
    "Data_path = '../Data/data_160_ori.csv'\n",
    "REPR_DIR = '../Reprs'\n",
    "\n",
    "repr_path= []\n",
    "for file in os.listdir(REPR_DIR):\n",
    "    if '.csv' in file:\n",
    "        path = REPR_DIR+ '/' + file\n",
    "        repr_path.append(path)\n",
    "\n",
    "df = pd.read_csv(Data_path, index_col=0)\n",
    "unimol_repr = pd.read_csv(repr_path[-2],index_col=0)\n",
    "sol_repr = pd.read_csv(repr_path[1],index_col=0)\n",
    "sol_oh = pd.read_csv(repr_path[3],index_col=0)\n",
    "# sol_oh = sol_oh[0:160]\n",
    "\n",
    "# concat required features\n",
    "fea_df = pd.concat([unimol_repr,sol_repr], axis=1)\n",
    "\n",
    "# Extract label colunm\n",
    "label_df = df['yields_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_27024\\1011703138.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'medium' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  ee.iloc[i] = 'medium'\n"
     ]
    }
   ],
   "source": [
    "# test yields\n",
    "# label Encoding\n",
    "le = LabelEncoder()\n",
    "label_le = le.fit_transform(label_df) #  0: high 1: low, 2: medium\n",
    "\n",
    "ee = df['ee'].copy()\n",
    "\n",
    "low = []\n",
    "med = []\n",
    "high = []\n",
    "\n",
    "for i in range(len(ee)):\n",
    "    if ee[i] >= 80:\n",
    "        high.append(i)\n",
    "        ee.iloc[i] = 'high'\n",
    "    elif ee[i] <= 20:\n",
    "        low.append(i)\n",
    "        ee.iloc[i] = 'low'\n",
    "    else:\n",
    "        med.append(i)\n",
    "        ee.iloc[i] = 'medium'\n",
    "label_df2 = ee\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "label_le2 = le2.fit_transform(label_df2) # medium 2, low 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [0.5714285714285714, 0.5428571428571428, 0.8333333333333334, 0.8, 0.6]\n",
      "Mean Accuracy: 0.6695\n",
      "Precisions: [0.19047619047619047, 0.2933333333333334, 0.4188034188034188, 0.26666666666666666, 0.3717948717948718]\n",
      "Mean Precision: 0.3082\n",
      "Recalls: [0.3333333333333333, 0.4488888888888889, 0.6533333333333333, 0.3333333333333333, 0.3803921568627451]\n",
      "Mean Recall: 0.4299\n",
      "F1 Scores: [0.24242424242424243, 0.3292307692307692, 0.4803921568627451, 0.29629629629629634, 0.34330011074197125]\n",
      "Mean F1 Score: 0.3383\n",
      "Confusion Matrices: [array([[ 0,  5,  0],\n",
      "       [ 0, 20,  0],\n",
      "       [ 0, 10,  0]], dtype=int64), array([[ 0,  7,  0],\n",
      "       [ 0, 17,  8],\n",
      "       [ 0,  1,  2]], dtype=int64), array([[ 1,  0,  0],\n",
      "       [ 0, 24,  1],\n",
      "       [ 2,  2,  0]], dtype=int64), array([[ 0,  1,  0],\n",
      "       [ 0, 24,  0],\n",
      "       [ 0,  5,  0]], dtype=int64), array([[ 0,  2,  1],\n",
      "       [ 0, 16,  1],\n",
      "       [ 0,  8,  2]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "X = fea_df  \n",
    "y = label_le\n",
    "groups = np.repeat(np.arange(32), 5)  # 每5条数据是一个组，总共有36组\n",
    "\n",
    "# 创建随机森林模型\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=93,         # 树的数量\n",
    "    max_depth=19,             # 树的最大深度，防止过拟合\n",
    "    min_samples_split=4,      # 内部节点再划分所需的最小样本数\n",
    "    min_samples_leaf=4,       # 叶节点所需的最小样本数\n",
    "    class_weight= {0: 4, 1: 1, 2: 2},  # 处理类别不均衡\n",
    "    max_features='sqrt',\n",
    "    random_state=42)\n",
    "\n",
    "# 创建 GroupKFold 对象\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# 存储每次测试集的评分\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# 进行分组交叉验证\n",
    "for train_idx, test_idx in gkf.split(X, y, groups=groups):\n",
    "    # print(\"Train indices:\", train_idx)\n",
    "    # print(\"Test indices:\", test_idx)\n",
    "    \n",
    "    # 使用 .iloc 基于整数位置索引划分数据集\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 计算各项评分\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    # 存储评分\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    confusion_matrices.append(confusion)\n",
    "\n",
    "# 输出每次交叉验证的准确率以及其他评分\n",
    "print(f\"Accuracies: {accuracies}\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n",
    "\n",
    "print(f\"Precisions: {precisions}\")\n",
    "print(f\"Mean Precision: {np.mean(precisions):.4f}\")\n",
    "\n",
    "print(f\"Recalls: {recalls}\")\n",
    "print(f\"Mean Recall: {np.mean(recalls):.4f}\")\n",
    "\n",
    "print(f\"F1 Scores: {f1_scores}\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores):.4f}\")\n",
    "\n",
    "# 输出混淆矩阵（每个折的混淆矩阵）\n",
    "print(f\"Confusion Matrices: {confusion_matrices}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 180 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read .csv format data\n",
    "Data_path = '../Data/data_180_ori.csv'\n",
    "REPR_DIR = '../Reprs'\n",
    "\n",
    "repr_path= []\n",
    "for file in os.listdir(REPR_DIR):\n",
    "    if '.csv' in file:\n",
    "        path = REPR_DIR+ '/' + file\n",
    "        repr_path.append(path)\n",
    "\n",
    "df = pd.read_csv(Data_path, index_col=0)\n",
    "unimol_repr = pd.read_csv(repr_path[-1],index_col=0)\n",
    "sol_repr = pd.read_csv(repr_path[2],index_col=0)\n",
    "\n",
    "# concat required features\n",
    "fea_df = pd.concat([unimol_repr,sol_repr], axis=1)\n",
    "\n",
    "# Extract label colunm\n",
    "label_df = df['yields_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_27024\\1011703138.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'medium' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  ee.iloc[i] = 'medium'\n"
     ]
    }
   ],
   "source": [
    "# test yields\n",
    "# label Encoding\n",
    "le = LabelEncoder()\n",
    "label_le = le.fit_transform(label_df) #  0: high 1: low, 2: medium\n",
    "\n",
    "ee = df['ee'].copy()\n",
    "\n",
    "low = []\n",
    "med = []\n",
    "high = []\n",
    "\n",
    "for i in range(len(ee)):\n",
    "    if ee[i] >= 80:\n",
    "        high.append(i)\n",
    "        ee.iloc[i] = 'high'\n",
    "    elif ee[i] <= 20:\n",
    "        low.append(i)\n",
    "        ee.iloc[i] = 'low'\n",
    "    else:\n",
    "        med.append(i)\n",
    "        ee.iloc[i] = 'medium'\n",
    "label_df2 = ee\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "label_le2 = le2.fit_transform(label_df2) # medium 2, low 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test indices: [  0   1   2   3   4  10  11  12  13  14  35  36  37  38  39  60  61  62\n",
      "  63  64 120 121 122 123 124 135 136 137 138 139 145 146 147 148 149 175\n",
      " 176 177 178 179]\n",
      "Test indices: [  5   6   7   8   9  30  31  32  33  34  55  56  57  58  59 115 116 117\n",
      " 118 119 140 141 142 143 144 165 166 167 168 169 170 171 172 173 174]\n",
      "Test indices: [ 25  26  27  28  29  50  51  52  53  54  75  76  77  78  79  80  81  82\n",
      "  83  84 110 111 112 113 114 130 131 132 133 134 160 161 162 163 164]\n",
      "Test indices: [ 20  21  22  23  24  45  46  47  48  49  70  71  72  73  74  85  86  87\n",
      "  88  89  95  96  97  98  99 105 106 107 108 109 155 156 157 158 159]\n",
      "Test indices: [ 15  16  17  18  19  40  41  42  43  44  65  66  67  68  69  90  91  92\n",
      "  93  94 100 101 102 103 104 125 126 127 128 129 150 151 152 153 154]\n",
      "Accuracies: [0.725, 0.7142857142857143, 0.6285714285714286, 0.7142857142857143, 0.6857142857142857]\n",
      "Mean Accuracy: 0.6936\n",
      "Precisions: [0.41228070175438597, 0.7924297924297924, 0.7133333333333334, 0.25252525252525254, 0.7987179487179489]\n",
      "Mean Precision: 0.5939\n",
      "Recalls: [0.36350574712643685, 0.5847578347578347, 0.5240879977722083, 0.30864197530864196, 0.6972559604138552]\n",
      "Mean Recall: 0.4956\n",
      "F1 Scores: [0.345273631840796, 0.611965811965812, 0.5474351356704298, 0.2777777777777778, 0.7180555555555556]\n",
      "Mean F1 Score: 0.5001\n",
      "Confusion Matrices: [array([[ 0,  3,  0],\n",
      "       [ 0, 28,  1],\n",
      "       [ 0,  7,  1]], dtype=int64), array([[ 1,  0,  3],\n",
      "       [ 0, 16,  2],\n",
      "       [ 0,  5,  8]], dtype=int64), array([[ 2,  4,  1],\n",
      "       [ 0, 16,  3],\n",
      "       [ 0,  5,  4]], dtype=int64), array([[ 0,  2,  0],\n",
      "       [ 2, 25,  0],\n",
      "       [ 0,  6,  0]], dtype=int64), array([[ 2,  0,  1],\n",
      "       [ 0, 11,  8],\n",
      "       [ 0,  2, 11]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "X = fea_df  \n",
    "y = label_le\n",
    "groups = np.repeat(np.arange(36), 5)  # 每5条数据是一个组，总共有36组\n",
    "\n",
    "# 创建随机森林模型\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=93,         # 树的数量\n",
    "    max_depth=19,             # 树的最大深度，防止过拟合\n",
    "    min_samples_split=4,      # 内部节点再划分所需的最小样本数\n",
    "    min_samples_leaf=4,       # 叶节点所需的最小样本数\n",
    "    class_weight= {0: 4, 1: 1, 2: 2},  # 处理类别不均衡\n",
    "    max_features='sqrt',\n",
    "    random_state=42)\n",
    "\n",
    "# 创建 GroupKFold 对象\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# 存储每次测试集的评分\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# 进行分组交叉验证\n",
    "for train_idx, test_idx in gkf.split(X, y, groups=groups):\n",
    "    # print(\"Train indices:\", train_idx)\n",
    "    print(\"Test indices:\", test_idx)\n",
    "    \n",
    "    # 使用 .iloc 基于整数位置索引划分数据集\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 计算各项评分\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    # 存储评分\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    confusion_matrices.append(confusion)\n",
    "\n",
    "# 输出每次交叉验证的准确率以及其他评分\n",
    "print(f\"Accuracies: {accuracies}\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n",
    "\n",
    "print(f\"Precisions: {precisions}\")\n",
    "print(f\"Mean Precision: {np.mean(precisions):.4f}\")\n",
    "\n",
    "print(f\"Recalls: {recalls}\")\n",
    "print(f\"Mean Recall: {np.mean(recalls):.4f}\")\n",
    "\n",
    "print(f\"F1 Scores: {f1_scores}\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores):.4f}\")\n",
    "\n",
    "# 输出混淆矩阵（每个折的混淆矩阵）\n",
    "print(f\"Confusion Matrices: {confusion_matrices}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unimol_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
