{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test aldol reaction data yields with classification models\n",
    "\n",
    "Because the data is imbalanced, we choose random forest model.\n",
    "1. try one-hot coding peptide and solvent\n",
    "2. try uninol repr peptide and onehot solvent\n",
    "3. try unimolrepr peptide and solvent \n",
    "4. try classes weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "\n",
    "# Import relevant scikit-learn modules\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Reprs/Solvent_Repr.csv',\n",
       " '../Reprs/Solvent_Repr_160.csv',\n",
       " '../Reprs/Solvent_Repr_180.csv',\n",
       " '../Reprs/sol_oh.csv',\n",
       " '../Reprs/sol_oh_180.csv',\n",
       " '../Reprs/UniMolRepr.csv',\n",
       " '../Reprs/UniMolRepr_160.csv',\n",
       " '../Reprs/UniMolRepr_180.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read .csv format data\n",
    "Data_path = '../Data/data_160_ori.csv'\n",
    "REPR_DIR = '../Reprs'\n",
    "\n",
    "repr_path= []\n",
    "for file in os.listdir(REPR_DIR):\n",
    "    if '.csv' in file:\n",
    "        path = REPR_DIR+ '/' + file\n",
    "        repr_path.append(path)\n",
    "\n",
    "repr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Data_path, index_col=0)\n",
    "unimol_repr = pd.read_csv(repr_path[-2],index_col=0)\n",
    "sol_repr = pd.read_csv(repr_path[1],index_col=0)\n",
    "sol_oh = pd.read_csv(repr_path[4],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_oh = sol_oh.iloc[:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat required features\n",
    "fea_df = pd.concat([unimol_repr,sol_repr], axis=1)\n",
    "\n",
    "# Extract label colunm\n",
    "label_df = df['yields_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       111\n",
       "medium     32\n",
       "high       17\n",
       "Name: yields_label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label Encoding\n",
    "le = LabelEncoder()\n",
    "label_le = le.fit_transform(label_df)\n",
    "\n",
    "# one-hot Encoding\n",
    "label_oh = pd.get_dummies(label_df, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2, 2, 2,\n",
       "       2, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 0, 1, 2, 0, 0, 2, 1,\n",
       "       2, 0, 2, 1, 1, 1, 1, 1, 0, 1, 2, 0, 0, 1, 1, 2, 0, 0, 1, 1, 2, 1,\n",
       "       2, 0, 1, 2, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_le"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try UniMOlRepr feature of peptide and solvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fea_df\n",
    "y = label_le\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [ 0 27  0]\n",
      " [ 0  0  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the resampled training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the original test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try OneHot peptide feature and OneHot solvent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGVL</th>\n",
       "      <th>APGG</th>\n",
       "      <th>APGP</th>\n",
       "      <th>GAPV</th>\n",
       "      <th>GGGP</th>\n",
       "      <th>GGLG</th>\n",
       "      <th>GLAA</th>\n",
       "      <th>GLGG</th>\n",
       "      <th>GLGP</th>\n",
       "      <th>GLLL</th>\n",
       "      <th>...</th>\n",
       "      <th>PPVL</th>\n",
       "      <th>VAPL</th>\n",
       "      <th>VGLG</th>\n",
       "      <th>VPAL</th>\n",
       "      <th>VPGL</th>\n",
       "      <th>DCE</th>\n",
       "      <th>DCM</th>\n",
       "      <th>MeCN</th>\n",
       "      <th>MeOH</th>\n",
       "      <th>iPrOH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGVL  APGG  APGP  GAPV  GGGP  GGLG  GLAA  GLGG  GLGP  GLLL  ...  PPVL  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   VAPL  VGLG  VPAL  VPGL  DCE  DCM  MeCN  MeOH  iPrOH  \n",
       "0     0     0     0     0    0    0     1     0      0  \n",
       "1     0     0     0     0    0    0     0     1      0  \n",
       "2     0     0     0     0    0    0     0     0      1  \n",
       "3     0     0     0     0    0    1     0     0      0  \n",
       "4     0     0     0     0    1    0     0     0      0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Onehot coding peptide\n",
    "fea_oh = pd.get_dummies(df['Peptide'], dtype=int)\n",
    "fea_oh = pd.concat([fea_oh,sol_oh], axis=1)\n",
    "fea_oh.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 2  1  0]\n",
      " [ 1 26  0]\n",
      " [ 1  1  0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       0.93      0.96      0.95        27\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.48      0.54      0.51        32\n",
      "weighted avg       0.83      0.88      0.85        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = fea_oh\n",
    "y = label_le\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the sampled training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the original test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try UnimolRepr peptide feature and OneHot solvent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [ 2 25  0]\n",
      " [ 1  1  0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         3\n",
      "           1       0.96      0.93      0.94        27\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.49      0.64      0.54        32\n",
      "weighted avg       0.86      0.88      0.86        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# concat feature\n",
    "fea_Uni_Oh = pd.concat([unimol_repr,sol_oh],axis=1)\n",
    "\n",
    "X = fea_Uni_Oh\n",
    "y = label_le\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the sampled training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the original test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try adjust classes weights on UniMolRepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 40**********************\n",
      "Confusion Matrix:\n",
      " [[ 4  1  0]\n",
      " [ 0 21  0]\n",
      " [ 0  3  3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.84      1.00      0.91        21\n",
      "           2       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.95      0.77      0.82        32\n",
      "weighted avg       0.90      0.88      0.86        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 41**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  1  1]\n",
      " [ 0 24  0]\n",
      " [ 2  2  0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         4\n",
      "           1       0.89      1.00      0.94        24\n",
      "           2       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.46      0.50      0.48        32\n",
      "weighted avg       0.73      0.81      0.77        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 42**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [ 0 27  0]\n",
      " [ 0  0  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 43**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  0]\n",
      " [ 0 27  1]\n",
      " [ 0  2  1]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       0.93      0.96      0.95        28\n",
      "           2       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.81      0.77      0.78        32\n",
      "weighted avg       0.89      0.91      0.90        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 44**********************\n",
      "Confusion Matrix:\n",
      " [[ 4  2  0]\n",
      " [ 0 19  1]\n",
      " [ 0  2  4]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.83      0.95      0.88        20\n",
      "           2       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.88      0.76      0.80        32\n",
      "weighted avg       0.85      0.84      0.84        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 45**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  2  2]\n",
      " [ 1 21  1]\n",
      " [ 1  0  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         6\n",
      "           1       0.91      0.91      0.91        23\n",
      "           2       0.40      0.67      0.50         3\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.60      0.64      0.60        32\n",
      "weighted avg       0.79      0.78      0.78        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 46**********************\n",
      "Confusion Matrix:\n",
      " [[ 6  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  4  4]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       0.81      0.94      0.87        18\n",
      "           2       0.80      0.50      0.62         8\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.87      0.81      0.83        32\n",
      "weighted avg       0.84      0.84      0.83        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 47**********************\n",
      "Confusion Matrix:\n",
      " [[ 4  1  0]\n",
      " [ 0 19  1]\n",
      " [ 1  4  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.79      0.95      0.86        20\n",
      "           2       0.67      0.29      0.40         7\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.75      0.68      0.69        32\n",
      "weighted avg       0.77      0.78      0.75        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 48**********************\n",
      "Confusion Matrix:\n",
      " [[ 4  1  0]\n",
      " [ 1 19  3]\n",
      " [ 0  2  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.86      0.83      0.84        23\n",
      "           2       0.40      0.50      0.44         4\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.69      0.71      0.70        32\n",
      "weighted avg       0.80      0.78      0.79        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 49**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  0  0]\n",
      " [ 1 23  2]\n",
      " [ 0  2  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       0.92      0.88      0.90        26\n",
      "           2       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.70      0.79      0.73        32\n",
      "weighted avg       0.85      0.84      0.85        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = fea_df\n",
    "y = label_le\n",
    "\n",
    "for i in range(40, 50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    class_weights = {0: 3, 1: 1, 2: 2} # O:High More important; 1: Medium Less important; 2: Low last important\n",
    "    rf_classifier = RandomForestClassifier(random_state=i, class_weight=class_weights) # class_weight=class_weights\n",
    "\n",
    "    # Train the classifier on the sampled training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the original test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'*********************Random State: {i}**********************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 40**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  1  1]\n",
      " [ 0 21  0]\n",
      " [ 0  2  4]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75         5\n",
      "           1       0.88      1.00      0.93        21\n",
      "           2       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.89      0.76      0.80        32\n",
      "weighted avg       0.88      0.88      0.87        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 41**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  1  0]\n",
      " [ 0 24  0]\n",
      " [ 2  1  1]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67         4\n",
      "           1       0.92      1.00      0.96        24\n",
      "           2       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.84      0.67      0.68        32\n",
      "weighted avg       0.89      0.88      0.85        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 42**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [ 0 27  0]\n",
      " [ 0  0  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 43**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  0]\n",
      " [ 0 28  0]\n",
      " [ 0  2  1]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       0.93      1.00      0.97        28\n",
      "           2       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.94        32\n",
      "   macro avg       0.98      0.78      0.82        32\n",
      "weighted avg       0.94      0.94      0.92        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 44**********************\n",
      "Confusion Matrix:\n",
      " [[ 4  2  0]\n",
      " [ 1 18  1]\n",
      " [ 0  3  3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.78      0.90      0.84        20\n",
      "           2       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.78      0.69      0.72        32\n",
      "weighted avg       0.78      0.78      0.77        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 45**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  2  2]\n",
      " [ 0 22  1]\n",
      " [ 0  0  3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         6\n",
      "           1       0.92      0.96      0.94        23\n",
      "           2       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.81      0.76      0.70        32\n",
      "weighted avg       0.89      0.84      0.83        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 46**********************\n",
      "Confusion Matrix:\n",
      " [[ 5  1  0]\n",
      " [ 0 18  0]\n",
      " [ 0  4  4]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91         6\n",
      "           1       0.78      1.00      0.88        18\n",
      "           2       1.00      0.50      0.67         8\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.93      0.78      0.82        32\n",
      "weighted avg       0.88      0.84      0.83        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 47**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  2  0]\n",
      " [ 0 19  1]\n",
      " [ 1  4  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67         5\n",
      "           1       0.76      0.95      0.84        20\n",
      "           2       0.67      0.29      0.40         7\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.73      0.61      0.64        32\n",
      "weighted avg       0.74      0.75      0.72        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 48**********************\n",
      "Confusion Matrix:\n",
      " [[ 4  1  0]\n",
      " [ 1 20  2]\n",
      " [ 0  2  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.87      0.87      0.87        23\n",
      "           2       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.72      0.72      0.72        32\n",
      "weighted avg       0.81      0.81      0.81        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 49**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  0  0]\n",
      " [ 1 23  2]\n",
      " [ 1  1  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         2\n",
      "           1       0.96      0.88      0.92        26\n",
      "           2       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.65      0.79      0.70        32\n",
      "weighted avg       0.87      0.84      0.85        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# without weighted\n",
    "X = fea_df\n",
    "y = label_le\n",
    "\n",
    "for i in range(40, 50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    # class_weights = {0: 9, 1: 1, 2: 3} # O:High More important; 1: Medium Less important; 2: Low last important\n",
    "    rf_classifier = RandomForestClassifier(random_state=i) # class_weight=class_weights\n",
    "\n",
    "    # Train the classifier on the sampled training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the original test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'*********************Random State: {i}**********************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "models = [RidgeClassifier(),\n",
    "          SGDClassifier(),\n",
    "          KNeighborsClassifier(n_neighbors=7), # use k = 7 as in papers\n",
    "          SVC(),\n",
    "          MLPClassifier(hidden_layer_sizes=(100), # 5-neurons are used in the initial\n",
    "                       activation='logistic',  # release of the paper\n",
    "                       solver='lbfgs',\n",
    "                       max_iter=1000,\n",
    "                       random_state=42),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Trained Model: RidgeClassifier()**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [ 1 23  1]\n",
      " [ 1  3  0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         3\n",
      "           1       0.88      0.92      0.90        25\n",
      "           2       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.49      0.64      0.55        32\n",
      "weighted avg       0.75      0.81      0.77        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Trained Model: SGDClassifier()**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [10  8  7]\n",
      " [ 0  1  3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      1.00      0.38         3\n",
      "           1       0.89      0.32      0.47        25\n",
      "           2       0.30      0.75      0.43         4\n",
      "\n",
      "    accuracy                           0.44        32\n",
      "   macro avg       0.47      0.69      0.42        32\n",
      "weighted avg       0.75      0.44      0.46        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Trained Model: KNeighborsClassifier(n_neighbors=7)**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  3  0]\n",
      " [ 0 23  2]\n",
      " [ 0  2  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.82      0.92      0.87        25\n",
      "           2       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.44      0.47      0.46        32\n",
      "weighted avg       0.70      0.78      0.74        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Trained Model: SVC()**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  3  0]\n",
      " [ 0 25  0]\n",
      " [ 0  4  0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.78      1.00      0.88        25\n",
      "           2       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.26      0.33      0.29        32\n",
      "weighted avg       0.61      0.78      0.69        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Trained Model: MLPClassifier(activation='logistic', hidden_layer_sizes=100, max_iter=1000,\n",
      "              random_state=42, solver='lbfgs')**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  2  0]\n",
      " [ 0 23  2]\n",
      " [ 0  2  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.85      0.92      0.88        25\n",
      "           2       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.78      0.58      0.63        32\n",
      "weighted avg       0.82      0.81      0.80        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = fea_df\n",
    "y = label_le\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # class_weights = {0: 3, 1: 2, 2: 1} # O:High More important; 1: Medium Less important; 2: Low last important\n",
    "    classifier = model\n",
    "\n",
    "    # Train the classifier on the sampled training data\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the original test set\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'*********************Trained Model: {model}**********************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 40**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  1  1]\n",
      " [ 1 18  2]\n",
      " [ 1  1  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33         3\n",
      "           1       0.90      0.86      0.88        21\n",
      "           2       0.40      0.50      0.44         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.54      0.56      0.55        28\n",
      "weighted avg       0.77      0.75      0.76        28\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 41**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  1  0]\n",
      " [ 0 20  2]\n",
      " [ 0  2  0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.87      0.91      0.89        22\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.62      0.55      0.58        28\n",
      "weighted avg       0.83      0.82      0.82        28\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 42**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  1  0]\n",
      " [ 0 20  1]\n",
      " [ 1  2  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         2\n",
      "           1       0.87      0.95      0.91        21\n",
      "           2       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.68      0.62      0.64        28\n",
      "weighted avg       0.81      0.82      0.81        28\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 43**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  1  0]\n",
      " [ 0 20  2]\n",
      " [ 0  1  1]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.91      0.91      0.91        22\n",
      "           2       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.86        28\n",
      "   macro avg       0.75      0.72      0.72        28\n",
      "weighted avg       0.88      0.86      0.87        28\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 44**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  1  3]\n",
      " [ 0 18  2]\n",
      " [ 0  2  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.86      0.90      0.88        20\n",
      "           2       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.38      0.47      0.41        28\n",
      "weighted avg       0.65      0.71      0.68        28\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/troy/miniconda3/envs/unimol-tool/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/troy/miniconda3/envs/unimol-tool/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/troy/miniconda3/envs/unimol-tool/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 45**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  0]\n",
      " [ 1 22  0]\n",
      " [ 0  2  2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.92      0.96      0.94        23\n",
      "           2       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.89        28\n",
      "   macro avg       0.81      0.82      0.76        28\n",
      "weighted avg       0.91      0.89      0.89        28\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 46**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  1]\n",
      " [ 0 19  2]\n",
      " [ 0  2  3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.90      0.90      0.90        21\n",
      "           2       0.50      0.60      0.55         5\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.80      0.67      0.71        28\n",
      "weighted avg       0.84      0.82      0.82        28\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 47**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  1  0]\n",
      " [ 0 21  0]\n",
      " [ 0  2  3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.88      1.00      0.93        21\n",
      "           2       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.89        28\n",
      "   macro avg       0.96      0.70      0.78        28\n",
      "weighted avg       0.91      0.89      0.88        28\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 48**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  0  1]\n",
      " [ 1 15  1]\n",
      " [ 1  3  4]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       0.83      0.88      0.86        17\n",
      "           2       0.67      0.50      0.57         8\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.67      0.68      0.67        28\n",
      "weighted avg       0.75      0.75      0.74        28\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 49**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  0  1]\n",
      " [ 0 19  1]\n",
      " [ 1  1  3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.95      0.95      0.95        20\n",
      "           2       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.86        28\n",
      "   macro avg       0.74      0.74      0.74        28\n",
      "weighted avg       0.86      0.86      0.86        28\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "fea_df = pd.concat([unimol_repr,sol_repr], axis=1)\n",
    "fea_df.columns = range(fea_df.shape[1])\n",
    "\n",
    "X = fea_df\n",
    "y = label_le\n",
    "\n",
    "for i in range(40, 50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    # scale_pos_weight = len(y_train[y_train == 2]) / len(y_train[y_train == 0])\n",
    "    xgb_classifier = xgb.XGBClassifier(objective='multi:softprob', num_class=3, random_state=i)\n",
    "\n",
    "    xgb_classifier.fit(X_train, y_train)\n",
    "    y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'*********************Random State: {i}**********************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
