{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test aldol reaction ee value with classification models\n",
    "\n",
    "1. check the data structure, make it less imbalanced.\n",
    "2. try uninol repr peptide and onehot solvent \n",
    "3. try unimolrepr peptide and solvent(Best performance)\n",
    "4. try classes weights and XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "\n",
    "# Import relevant scikit-learn modules\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import ModelFits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Reprs/Solvent_Repr.csv',\n",
       " '../Reprs/Solvent_Repr_160.csv',\n",
       " '../Reprs/Solvent_Repr_180.csv',\n",
       " '../Reprs/sol_oh.csv',\n",
       " '../Reprs/sol_oh_180.csv',\n",
       " '../Reprs/UniMolRepr.csv',\n",
       " '../Reprs/UniMolRepr_160.csv',\n",
       " '../Reprs/UniMolRepr_180.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read .csv format data\n",
    "Data_path = '../Data/data_160_ori.csv'\n",
    "REPR_DIR = '../Reprs'\n",
    "\n",
    "repr_path= []\n",
    "for file in os.listdir(REPR_DIR):\n",
    "    if '.csv' in file:\n",
    "        path = REPR_DIR+ '/' + file\n",
    "        repr_path.append(path)\n",
    "\n",
    "repr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Data_path, index_col=0)\n",
    "unimol_repr = pd.read_csv(repr_path[-2],index_col=0)\n",
    "sol_repr = pd.read_csv(repr_path[1],index_col=0)\n",
    "sol_oh = pd.read_csv(repr_path[3],index_col=0)\n",
    "sol_oh = sol_oh[0:160]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Data Sturcture and distribute to 3 level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 100, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee = df['ee'].copy()\n",
    "\n",
    "low = []\n",
    "med = []\n",
    "high = []\n",
    "\n",
    "for i in range(len(ee)):\n",
    "    if ee[i] >= 80:\n",
    "        high.append(i)\n",
    "        ee.iloc[i] = 'high'\n",
    "    elif ee[i] <= 20:\n",
    "        low.append(i)\n",
    "        ee.iloc[i] = 'low'\n",
    "    else:\n",
    "        med.append(i)\n",
    "        ee.iloc[i] = 'medium'\n",
    "\n",
    "len(low),len(med),len(high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat required features\n",
    "fea_df = pd.concat([unimol_repr,sol_repr], axis=1)\n",
    "\n",
    "# Extract label colunm\n",
    "label_df = ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label Encoding\n",
    "le = LabelEncoder()\n",
    "label_le = le.fit_transform(label_df) # 2:Medium; 1: Low; 0:High\n",
    "\n",
    "# one-hot Encoding\n",
    "label_oh = pd.get_dummies(label_df, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1,\n",
       "       2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       0, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 1, 2, 2, 2, 0, 2, 0, 0, 0, 2, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 0, 2, 2, 2, 2, 1, 2, 2, 2, 1,\n",
       "       2, 1, 1, 2, 2, 2, 1, 2, 0, 2, 0, 2, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_le"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try UniMOlRepr feature of peptide and solvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fea_df\n",
    "y = label_le\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 2  0  1]\n",
      " [ 0  4  6]\n",
      " [ 0  3 16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.57      0.40      0.47        10\n",
      "           2       0.70      0.84      0.76        19\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.76      0.64      0.68        32\n",
      "weighted avg       0.69      0.69      0.67        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the resampled training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the original test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try OneHot peptide feature and OneHot solvent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGVL</th>\n",
       "      <th>APGG</th>\n",
       "      <th>APGP</th>\n",
       "      <th>GAPV</th>\n",
       "      <th>GGGP</th>\n",
       "      <th>GGLG</th>\n",
       "      <th>GLAA</th>\n",
       "      <th>GLGG</th>\n",
       "      <th>GLGP</th>\n",
       "      <th>GLLL</th>\n",
       "      <th>...</th>\n",
       "      <th>PPVL</th>\n",
       "      <th>VAPL</th>\n",
       "      <th>VGLG</th>\n",
       "      <th>VPAL</th>\n",
       "      <th>VPGL</th>\n",
       "      <th>DCE</th>\n",
       "      <th>DCM</th>\n",
       "      <th>MeCN</th>\n",
       "      <th>MeOH</th>\n",
       "      <th>iPrOH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGVL  APGG  APGP  GAPV  GGGP  GGLG  GLAA  GLGG  GLGP  GLLL  ...  PPVL  \\\n",
       "0       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "155     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "156     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "157     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "158     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "159     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "     VAPL  VGLG  VPAL  VPGL  DCE  DCM  MeCN  MeOH  iPrOH  \n",
       "0       0     0     0     0    0    0     1     0      0  \n",
       "1       0     0     0     0    0    0     0     1      0  \n",
       "2       0     0     0     0    0    0     0     0      1  \n",
       "3       0     0     0     0    0    1     0     0      0  \n",
       "4       0     0     0     0    1    0     0     0      0  \n",
       "..    ...   ...   ...   ...  ...  ...   ...   ...    ...  \n",
       "155     0     0     1     0    0    0     1     0      0  \n",
       "156     0     0     1     0    0    0     0     1      0  \n",
       "157     0     0     1     0    0    0     0     0      1  \n",
       "158     0     0     1     0    0    1     0     0      0  \n",
       "159     0     0     1     0    1    0     0     0      0  \n",
       "\n",
       "[160 rows x 37 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Onehot coding peptide\n",
    "fea_oh = pd.get_dummies(df['Peptide'], dtype=int)\n",
    "fea_oh = pd.concat([fea_oh,sol_oh], axis=1)\n",
    "fea_oh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 40**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  2]\n",
      " [ 0  7  3]\n",
      " [ 0  2 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.78      0.70      0.74        10\n",
      "           2       0.78      0.90      0.84        20\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.52      0.53      0.52        32\n",
      "weighted avg       0.73      0.78      0.75        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 41**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0]\n",
      " [ 0  3  6]\n",
      " [ 1  2 20]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.60      0.33      0.43         9\n",
      "           2       0.77      0.87      0.82        23\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.46      0.40      0.41        32\n",
      "weighted avg       0.72      0.72      0.71        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 42**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  2]\n",
      " [ 0  5  5]\n",
      " [ 0  4 15]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.56      0.50      0.53        10\n",
      "           2       0.68      0.79      0.73        19\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.75      0.54      0.59        32\n",
      "weighted avg       0.67      0.66      0.65        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 43**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  1]\n",
      " [ 0  7  5]\n",
      " [ 0  0 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       1.00      0.58      0.74        12\n",
      "           2       0.75      1.00      0.86        18\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.92      0.69      0.75        32\n",
      "weighted avg       0.86      0.81      0.80        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 44**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  1]\n",
      " [ 0  6  2]\n",
      " [ 2  4 16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         2\n",
      "           1       0.60      0.75      0.67         8\n",
      "           2       0.84      0.73      0.78        22\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.59      0.66      0.62        32\n",
      "weighted avg       0.75      0.72      0.73        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 45**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  1]\n",
      " [ 0  6  4]\n",
      " [ 0  3 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.67      0.60      0.63        10\n",
      "           2       0.78      0.86      0.82        21\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.48      0.49      0.48        32\n",
      "weighted avg       0.72      0.75      0.73        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 46**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  1  2]\n",
      " [ 0  5  1]\n",
      " [ 0  5 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.45      0.83      0.59         6\n",
      "           2       0.86      0.78      0.82        23\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.44      0.54      0.47        32\n",
      "weighted avg       0.70      0.72      0.70        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 47**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  3]\n",
      " [ 0  6  3]\n",
      " [ 0  0 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         4\n",
      "           1       1.00      0.67      0.80         9\n",
      "           2       0.76      1.00      0.86        19\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.92      0.64      0.69        32\n",
      "weighted avg       0.86      0.81      0.79        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 48**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [ 0  6  4]\n",
      " [ 0  0 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      0.60      0.75        10\n",
      "           2       0.83      1.00      0.90        19\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.94      0.87      0.88        32\n",
      "weighted avg       0.90      0.88      0.87        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 49**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  1]\n",
      " [ 0  5  5]\n",
      " [ 0  4 17]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.56      0.50      0.53        10\n",
      "           2       0.74      0.81      0.77        21\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.43      0.44      0.43        32\n",
      "weighted avg       0.66      0.69      0.67        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = fea_oh\n",
    "y = label_le\n",
    "\n",
    "for i in range (40,50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Train the classifier on the sampled training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the original test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'*********************Random State: {i}**********************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try UnimolRepr peptide feature and OneHot solvent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 40**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  2]\n",
      " [ 0  5  5]\n",
      " [ 0  2 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.71      0.50      0.59        10\n",
      "           2       0.72      0.90      0.80        20\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.48      0.47      0.46        32\n",
      "weighted avg       0.67      0.72      0.68        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 41**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0]\n",
      " [ 1  5  3]\n",
      " [ 2  4 17]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.56      0.56      0.56         9\n",
      "           2       0.85      0.74      0.79        23\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.47      0.43      0.45        32\n",
      "weighted avg       0.77      0.69      0.72        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 42**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  0  1]\n",
      " [ 0  3  7]\n",
      " [ 0  3 16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.50      0.30      0.37        10\n",
      "           2       0.67      0.84      0.74        19\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.72      0.60      0.64        32\n",
      "weighted avg       0.65      0.66      0.63        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 43**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  1]\n",
      " [ 0  8  4]\n",
      " [ 0  2 16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.80      0.67      0.73        12\n",
      "           2       0.76      0.89      0.82        18\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.85      0.69      0.74        32\n",
      "weighted avg       0.79      0.78      0.78        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 44**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  1]\n",
      " [ 0  4  4]\n",
      " [ 2  2 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         2\n",
      "           1       0.67      0.50      0.57         8\n",
      "           2       0.78      0.82      0.80        22\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.59      0.61      0.59        32\n",
      "weighted avg       0.73      0.72      0.72        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 45**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  1]\n",
      " [ 0  6  4]\n",
      " [ 2  3 16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.67      0.60      0.63        10\n",
      "           2       0.76      0.76      0.76        21\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.48      0.45      0.46        32\n",
      "weighted avg       0.71      0.69      0.70        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 46**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  1  0]\n",
      " [ 0  4  2]\n",
      " [ 0  4 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.44      0.67      0.53         6\n",
      "           2       0.90      0.83      0.86        23\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.78      0.72      0.73        32\n",
      "weighted avg       0.83      0.78      0.80        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 47**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  0  1]\n",
      " [ 0  5  4]\n",
      " [ 0  0 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       1.00      0.56      0.71         9\n",
      "           2       0.79      1.00      0.88        19\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.93      0.77      0.82        32\n",
      "weighted avg       0.88      0.84      0.83        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 48**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [ 0  5  5]\n",
      " [ 0  3 16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       0.62      0.50      0.56        10\n",
      "           2       0.76      0.84      0.80        19\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.80      0.78      0.79        32\n",
      "weighted avg       0.74      0.75      0.74        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 49**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  1]\n",
      " [ 0  6  4]\n",
      " [ 0  7 14]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.46      0.60      0.52        10\n",
      "           2       0.74      0.67      0.70        21\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.40      0.42      0.41        32\n",
      "weighted avg       0.63      0.62      0.62        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# concat feature\n",
    "fea_Uni_Oh = pd.concat([unimol_repr,sol_oh],axis=1)\n",
    "\n",
    "X = fea_Uni_Oh\n",
    "y = label_le\n",
    "for i in range(40,50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Train the classifier on the sampled training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the original test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'*********************Random State: {i}**********************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try adjust classes weights on UniMolRepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 40**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  2]\n",
      " [ 0  6  4]\n",
      " [ 0  3 17]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.67      0.60      0.63        10\n",
      "           2       0.74      0.85      0.79        20\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.47      0.48      0.47        32\n",
      "weighted avg       0.67      0.72      0.69        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 41**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0]\n",
      " [ 1  5  3]\n",
      " [ 3  2 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.71      0.56      0.63         9\n",
      "           2       0.86      0.78      0.82        23\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.52      0.45      0.48        32\n",
      "weighted avg       0.82      0.72      0.76        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 42**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  0  1]\n",
      " [ 0  6  4]\n",
      " [ 0  3 16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.67      0.60      0.63        10\n",
      "           2       0.76      0.84      0.80        19\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.81      0.70      0.74        32\n",
      "weighted avg       0.75      0.75      0.75        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 43**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  1]\n",
      " [ 0  7  5]\n",
      " [ 0  4 14]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.64      0.58      0.61        12\n",
      "           2       0.70      0.78      0.74        18\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.78      0.62      0.67        32\n",
      "weighted avg       0.69      0.69      0.68        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 44**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  1]\n",
      " [ 0  5  3]\n",
      " [ 2  3 17]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         2\n",
      "           1       0.62      0.62      0.62         8\n",
      "           2       0.81      0.77      0.79        22\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.59      0.63      0.61        32\n",
      "weighted avg       0.73      0.72      0.72        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 45**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  1]\n",
      " [ 1  6  3]\n",
      " [ 0  0 21]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.60      0.75        10\n",
      "           2       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.61      0.53      0.55        32\n",
      "weighted avg       0.86      0.84      0.83        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 46**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  1  1]\n",
      " [ 0  4  2]\n",
      " [ 1  3 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.50      0.67      0.57         6\n",
      "           2       0.86      0.83      0.84        23\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.62      0.61      0.61        32\n",
      "weighted avg       0.76      0.75      0.75        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 47**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  0  2]\n",
      " [ 0  6  3]\n",
      " [ 0  0 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       1.00      0.67      0.80         9\n",
      "           2       0.79      1.00      0.88        19\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.93      0.72      0.78        32\n",
      "weighted avg       0.88      0.84      0.83        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 48**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  0  1]\n",
      " [ 0  6  4]\n",
      " [ 1  2 16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.75      0.60      0.67        10\n",
      "           2       0.76      0.84      0.80        19\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.73      0.70      0.71        32\n",
      "weighted avg       0.75      0.75      0.75        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 49**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  1]\n",
      " [ 0  6  4]\n",
      " [ 0  5 16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.55      0.60      0.57        10\n",
      "           2       0.76      0.76      0.76        21\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.44      0.45      0.44        32\n",
      "weighted avg       0.67      0.69      0.68        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\unimol_tools\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = fea_df\n",
    "y = label_le\n",
    "\n",
    "for i in range(40, 50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    class_weights = {0: 4, 1: 1, 2: 2} # O:High More important; 1: Low Last important; 2: Medium: less important\n",
    "    rf_classifier = RandomForestClassifier(random_state=42,class_weight=class_weights) # class_weight=class_weights\n",
    "\n",
    "    # Train the classifier on the sampled training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the original test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'*********************Random State: {i}**********************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "models = [RidgeClassifier(),\n",
    "          SGDClassifier(),\n",
    "          KNeighborsClassifier(), # use k = 7 as in papers\n",
    "          SVC(),\n",
    "          MLPClassifier(hidden_layer_sizes=(100), # 5-neurons are used in the initial\n",
    "                       activation='logistic',  # release of the paper\n",
    "                       solver='lbfgs',\n",
    "                       max_iter=1000,\n",
    "                       random_state=42),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Trained Model: RidgeClassifier()**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  0  1]\n",
      " [ 0  4  6]\n",
      " [ 0  3 16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.57      0.40      0.47        10\n",
      "           2       0.70      0.84      0.76        19\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.76      0.64      0.68        32\n",
      "weighted avg       0.69      0.69      0.67        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Trained Model: SGDClassifier()**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  3]\n",
      " [ 0  1  9]\n",
      " [ 0  0 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       1.00      0.10      0.18        10\n",
      "           2       0.61      1.00      0.76        19\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.54      0.37      0.31        32\n",
      "weighted avg       0.68      0.62      0.51        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Trained Model: KNeighborsClassifier()**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  3]\n",
      " [ 0  3  7]\n",
      " [ 0  4 15]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.43      0.30      0.35        10\n",
      "           2       0.60      0.79      0.68        19\n",
      "\n",
      "    accuracy                           0.56        32\n",
      "   macro avg       0.34      0.36      0.34        32\n",
      "weighted avg       0.49      0.56      0.52        32\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Trained Model: SVC()**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  3]\n",
      " [ 0  0 10]\n",
      " [ 0  0 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.59      1.00      0.75        19\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.20      0.33      0.25        32\n",
      "weighted avg       0.35      0.59      0.44        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Trained Model: MLPClassifier(activation='logistic', hidden_layer_sizes=100, max_iter=1000,\n",
      "              random_state=42, solver='lbfgs')**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  2]\n",
      " [ 0  6  4]\n",
      " [ 0  5 14]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.55      0.60      0.57        10\n",
      "           2       0.70      0.74      0.72        19\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.75      0.56      0.60        32\n",
      "weighted avg       0.68      0.66      0.65        32\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = fea_df\n",
    "y = label_le\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # class_weights = {0: 3, 1: 2, 2: 1} # O:High More important; 1: Medium Less important; 2: Low last important\n",
    "    classifier = model\n",
    "\n",
    "    # Train the classifier on the sampled training data\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the original test set\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'*********************Trained Model: {model}**********************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 40**********************\n",
      "Confusion Matrix:\n",
      " [[ 4  0  0]\n",
      " [ 1  6  5]\n",
      " [ 2  2 15]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73         4\n",
      "           1       0.75      0.50      0.60        12\n",
      "           2       0.75      0.79      0.77        19\n",
      "\n",
      "    accuracy                           0.71        35\n",
      "   macro avg       0.69      0.76      0.70        35\n",
      "weighted avg       0.73      0.71      0.71        35\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 41**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  0  3]\n",
      " [ 1  6  2]\n",
      " [ 1  7 13]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.40      0.44         5\n",
      "           1       0.46      0.67      0.55         9\n",
      "           2       0.72      0.62      0.67        21\n",
      "\n",
      "    accuracy                           0.60        35\n",
      "   macro avg       0.56      0.56      0.55        35\n",
      "weighted avg       0.62      0.60      0.60        35\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 42**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  1  2]\n",
      " [ 0  9  6]\n",
      " [ 2  1 12]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.40      0.44         5\n",
      "           1       0.82      0.60      0.69        15\n",
      "           2       0.60      0.80      0.69        15\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.64      0.60      0.61        35\n",
      "weighted avg       0.68      0.66      0.65        35\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 43**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [ 0  7  3]\n",
      " [ 1  6 15]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       0.54      0.70      0.61        10\n",
      "           2       0.83      0.68      0.75        22\n",
      "\n",
      "    accuracy                           0.71        35\n",
      "   macro avg       0.71      0.79      0.74        35\n",
      "weighted avg       0.74      0.71      0.72        35\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 44**********************\n",
      "Confusion Matrix:\n",
      " [[ 4  0  1]\n",
      " [ 0  5  5]\n",
      " [ 1  1 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.83      0.50      0.62        10\n",
      "           2       0.75      0.90      0.82        20\n",
      "\n",
      "    accuracy                           0.77        35\n",
      "   macro avg       0.79      0.73      0.75        35\n",
      "weighted avg       0.78      0.77      0.76        35\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 45**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  1  0]\n",
      " [ 0  3  4]\n",
      " [ 1  4 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.38      0.43      0.40         7\n",
      "           2       0.83      0.79      0.81        24\n",
      "\n",
      "    accuracy                           0.71        35\n",
      "   macro avg       0.65      0.66      0.65        35\n",
      "weighted avg       0.73      0.71      0.72        35\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 46**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  1  0]\n",
      " [ 0  4  9]\n",
      " [ 1  1 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         2\n",
      "           1       0.67      0.31      0.42        13\n",
      "           2       0.67      0.90      0.77        20\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.61      0.57      0.56        35\n",
      "weighted avg       0.66      0.66      0.62        35\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 47**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  1]\n",
      " [ 0  8  3]\n",
      " [ 0  3 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.73      0.73      0.73        11\n",
      "           2       0.83      0.86      0.84        22\n",
      "\n",
      "    accuracy                           0.80        35\n",
      "   macro avg       0.85      0.70      0.75        35\n",
      "weighted avg       0.80      0.80      0.80        35\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 48**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  1]\n",
      " [ 0  8  2]\n",
      " [ 0  3 20]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.73      0.80      0.76        10\n",
      "           2       0.87      0.87      0.87        23\n",
      "\n",
      "    accuracy                           0.83        35\n",
      "   macro avg       0.87      0.72      0.77        35\n",
      "weighted avg       0.84      0.83      0.83        35\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 49**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  1  0]\n",
      " [ 0  6  3]\n",
      " [ 0  4 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.55      0.67      0.60         9\n",
      "           2       0.86      0.83      0.84        23\n",
      "\n",
      "    accuracy                           0.77        35\n",
      "   macro avg       0.80      0.72      0.75        35\n",
      "weighted avg       0.79      0.77      0.78        35\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "fea_df = pd.concat([unimol_repr,sol_repr], axis=1)\n",
    "fea_df.columns = range(fea_df.shape[1])\n",
    "\n",
    "X = fea_df\n",
    "\n",
    "for i in range(40, 50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    # scale_pos_weight = len(y_train[y_train == 2]) / len(y_train[y_train == 0])\n",
    "    xgb_classifier = xgb.XGBClassifier(objective='multi:softprob', num_class=3, random_state=i)\n",
    "\n",
    "    xgb_classifier.fit(X_train, y_train)\n",
    "    y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'*********************Random State: {i}**********************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
