{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling on imbalanced datasets\n",
    "\n",
    "Because the data is imbalanced, we will try oversampling methond.\n",
    "We choose random forest model, for weighted training.\n",
    "1. Duplicate small scale data, to balanced the ratil of datasets.\n",
    "2. Try normal distribution data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "\n",
    "# Import relevant scikit-learn modules\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from unimol_tools import UniMolRepr\n",
    "\n",
    "import utils\n",
    "from utils import oversample, class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Reprs/Solvent_Repr.csv',\n",
       " '../Reprs/Solvent_Repr_160.csv',\n",
       " '../Reprs/Solvent_Repr_180.csv',\n",
       " '../Reprs/sol_oh.csv',\n",
       " '../Reprs/sol_oh_180.csv',\n",
       " '../Reprs/UniMolRepr.csv',\n",
       " '../Reprs/UniMolRepr_160.csv',\n",
       " '../Reprs/UniMolRepr_180.csv']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read .csv format data\n",
    "DATA_DIR = '../Reprs'\n",
    "\n",
    "data_path= []\n",
    "for file in os.listdir(DATA_DIR):\n",
    "    if '.csv' in file:\n",
    "        path = DATA_DIR+ '/' + file\n",
    "        data_path.append(path)\n",
    "\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/data_180_ori_2.csv', index_col=0) # original data\n",
    "unimol_repr = pd.read_csv(data_path[-1],index_col=0) # unimol repr of peptides\n",
    "sol_repr = pd.read_csv(data_path[2],index_col=0) # unimol repr of solvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat required features\n",
    "fea_df = pd.concat([unimol_repr,sol_repr], axis=1)\n",
    "\n",
    "# Extract label colunm\n",
    "label_df = df['yields'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yields\n",
       "2    119\n",
       "1     35\n",
       "0     26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(label_df)):\n",
    "    if label_df.iloc[i] == 'low':\n",
    "        label_df.iloc[i] = 2\n",
    "    elif label_df.iloc[i] == 'medium':\n",
    "        label_df.iloc[i] = 1\n",
    "    else:\n",
    "        label_df.iloc[i] = 0\n",
    "\n",
    "label_df.astype(int)\n",
    "label_df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try oversampling on yields prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fea_df\n",
    "y = label_df.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 5  1  2]\n",
      " [ 0  4  2]\n",
      " [ 0  3 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77         8\n",
      "           1       0.50      0.67      0.57         6\n",
      "           2       0.83      0.86      0.84        22\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.78      0.72      0.73        36\n",
      "weighted avg       0.81      0.78      0.78        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = oversample(X_train, y_train, X, y, high_scale=2, medium_scale=2) # oversampling\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "# y_train = y_train.values.ravel()\n",
    "\n",
    "# Train the classifier on the resampled training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the original test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************The 40 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 2  1  6]\n",
      " [ 0  5  3]\n",
      " [ 0  0 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.22      0.36         9\n",
      "           1       0.83      0.62      0.71         8\n",
      "           2       0.68      1.00      0.81        19\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.84      0.62      0.63        36\n",
      "weighted avg       0.79      0.72      0.68        36\n",
      "\n",
      "******************************The 41 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 4  1  1]\n",
      " [ 0  6  2]\n",
      " [ 0  3 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.60      0.75      0.67         8\n",
      "           2       0.86      0.86      0.86        22\n",
      "\n",
      "    accuracy                           0.81        36\n",
      "   macro avg       0.82      0.76      0.78        36\n",
      "weighted avg       0.83      0.81      0.81        36\n",
      "\n",
      "******************************The 42 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 5  2  1]\n",
      " [ 0  4  2]\n",
      " [ 0  4 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77         8\n",
      "           1       0.40      0.67      0.50         6\n",
      "           2       0.86      0.82      0.84        22\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.75      0.70      0.70        36\n",
      "weighted avg       0.81      0.75      0.77        36\n",
      "\n",
      "******************************The 43 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 4  1  1]\n",
      " [ 0  2  3]\n",
      " [ 1  3 21]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.33      0.40      0.36         5\n",
      "           2       0.84      0.84      0.84        25\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.66      0.64      0.64        36\n",
      "weighted avg       0.76      0.75      0.76        36\n",
      "\n",
      "******************************The 44 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [ 0  8  1]\n",
      " [ 1  6 17]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       0.57      0.89      0.70         9\n",
      "           2       0.94      0.71      0.81        24\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.76      0.87      0.79        36\n",
      "weighted avg       0.83      0.78      0.79        36\n",
      "\n",
      "******************************The 45 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 5  1  0]\n",
      " [ 1  5  1]\n",
      " [ 0  2 21]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       0.62      0.71      0.67         7\n",
      "           2       0.95      0.91      0.93        23\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.80      0.82      0.81        36\n",
      "weighted avg       0.87      0.86      0.86        36\n",
      "\n",
      "******************************The 46 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  3]\n",
      " [ 0  6  4]\n",
      " [ 0  1 21]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         4\n",
      "           1       0.86      0.60      0.71        10\n",
      "           2       0.75      0.95      0.84        22\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.87      0.60      0.65        36\n",
      "weighted avg       0.81      0.78      0.75        36\n",
      "\n",
      "******************************The 47 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 3  2  2]\n",
      " [ 0  3  0]\n",
      " [ 1  1 24]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.43      0.55         7\n",
      "           1       0.50      1.00      0.67         3\n",
      "           2       0.92      0.92      0.92        26\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.72      0.78      0.71        36\n",
      "weighted avg       0.85      0.83      0.83        36\n",
      "\n",
      "******************************The 48 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 3  1  2]\n",
      " [ 0  5  1]\n",
      " [ 0  5 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         6\n",
      "           1       0.45      0.83      0.59         6\n",
      "           2       0.86      0.79      0.83        24\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.77      0.71      0.69        36\n",
      "weighted avg       0.82      0.75      0.76        36\n",
      "\n",
      "******************************The 49 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  1]\n",
      " [ 0  4  1]\n",
      " [ 2  3 25]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.57      0.80      0.67         5\n",
      "           2       0.93      0.83      0.88        30\n",
      "\n",
      "    accuracy                           0.81        36\n",
      "   macro avg       0.50      0.54      0.51        36\n",
      "weighted avg       0.85      0.81      0.82        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random split 10 times, without setting class weights\n",
    "\n",
    "X = fea_df\n",
    "y = label_df.astype(int)\n",
    "\n",
    "for seed in range(40,50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    X_train, y_train = oversample(X_train, y_train, X, y, high_scale=8, medium_scale=4) # oversampling\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "    y_train = y_train.values.ravel()\n",
    "\n",
    "    # Train the classifier on the resampled training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the original test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'******************************The {seed} seed run*********************************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try adjust classes weights on UniMolRepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Random State: 40**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  2  5]\n",
      " [ 1  4  3]\n",
      " [ 0  0 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.22      0.33         9\n",
      "           1       0.67      0.50      0.57         8\n",
      "           2       0.70      1.00      0.83        19\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.68      0.57      0.58        36\n",
      "weighted avg       0.69      0.69      0.65        36\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 41**********************\n",
      "Confusion Matrix:\n",
      " [[ 4  0  2]\n",
      " [ 0  6  2]\n",
      " [ 0  2 20]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.75      0.75      0.75         8\n",
      "           2       0.83      0.91      0.87        22\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.86      0.78      0.81        36\n",
      "weighted avg       0.84      0.83      0.83        36\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 42**********************\n",
      "Confusion Matrix:\n",
      " [[ 5  1  2]\n",
      " [ 0  4  2]\n",
      " [ 0  3 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77         8\n",
      "           1       0.50      0.67      0.57         6\n",
      "           2       0.83      0.86      0.84        22\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.78      0.72      0.73        36\n",
      "weighted avg       0.81      0.78      0.78        36\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 43**********************\n",
      "Confusion Matrix:\n",
      " [[ 5  1  0]\n",
      " [ 0  2  3]\n",
      " [ 1  3 21]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       0.33      0.40      0.36         5\n",
      "           2       0.88      0.84      0.86        25\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.68      0.69      0.68        36\n",
      "weighted avg       0.79      0.78      0.78        36\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 44**********************\n",
      "Confusion Matrix:\n",
      " [[ 2  0  1]\n",
      " [ 0  8  1]\n",
      " [ 1  5 18]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.62      0.89      0.73         9\n",
      "           2       0.90      0.75      0.82        24\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.73      0.77      0.74        36\n",
      "weighted avg       0.81      0.78      0.78        36\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 45**********************\n",
      "Confusion Matrix:\n",
      " [[ 4  2  0]\n",
      " [ 1  5  1]\n",
      " [ 0  2 21]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.56      0.71      0.63         7\n",
      "           2       0.95      0.91      0.93        23\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.77      0.76      0.76        36\n",
      "weighted avg       0.85      0.83      0.84        36\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 46**********************\n",
      "Confusion Matrix:\n",
      " [[ 1  0  3]\n",
      " [ 0  7  3]\n",
      " [ 0  1 21]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         4\n",
      "           1       0.88      0.70      0.78        10\n",
      "           2       0.78      0.95      0.86        22\n",
      "\n",
      "    accuracy                           0.81        36\n",
      "   macro avg       0.88      0.63      0.68        36\n",
      "weighted avg       0.83      0.81      0.78        36\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 47**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  2  2]\n",
      " [ 0  3  0]\n",
      " [ 1  1 24]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.43      0.55         7\n",
      "           1       0.50      1.00      0.67         3\n",
      "           2       0.92      0.92      0.92        26\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.72      0.78      0.71        36\n",
      "weighted avg       0.85      0.83      0.83        36\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 48**********************\n",
      "Confusion Matrix:\n",
      " [[ 3  1  2]\n",
      " [ 0  5  1]\n",
      " [ 1  2 21]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.50      0.60         6\n",
      "           1       0.62      0.83      0.71         6\n",
      "           2       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.81        36\n",
      "   macro avg       0.75      0.74      0.73        36\n",
      "weighted avg       0.81      0.81      0.80        36\n",
      "\n",
      "-------------------------------------------------------------\n",
      "*********************Random State: 49**********************\n",
      "Confusion Matrix:\n",
      " [[ 0  0  1]\n",
      " [ 0  4  1]\n",
      " [ 1  3 26]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.57      0.80      0.67         5\n",
      "           2       0.93      0.87      0.90        30\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.50      0.56      0.52        36\n",
      "weighted avg       0.85      0.83      0.84        36\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = fea_df\n",
    "y = label_df.astype(int)\n",
    "\n",
    "for seed in range(40, 50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    X_train, y_train = oversample(X_train, y_train, X, y, high_scale=8, medium_scale=4) # oversampling\n",
    "    \n",
    "    class_weights = {0: 3, 1: 2, 2: 1} # O:High More important; 1: Medium Less important; 2: Low last important\n",
    "    rf_classifier = RandomForestClassifier(random_state=seed, class_weight=class_weights) # class_weight=class_weights\n",
    "\n",
    "    # Train the classifier on the sampled training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the original test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'*********************Random State: {seed}**********************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on ee values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ee\n",
       "1    107\n",
       "2     54\n",
       "0     19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = class_label(df['ee'].copy())\n",
    "\n",
    "for i in range(len(label_df)):\n",
    "    if label_df.iloc[i] == 'low':\n",
    "        label_df.iloc[i] = 2\n",
    "    elif label_df.iloc[i] == 'medium':\n",
    "        label_df.iloc[i] = 1\n",
    "    else:\n",
    "        label_df.iloc[i] = 0\n",
    "\n",
    "label_df.astype(int)\n",
    "label_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************The 40 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 5  2  0]\n",
      " [ 1 13  4]\n",
      " [ 0  4  7]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77         7\n",
      "           1       0.68      0.72      0.70        18\n",
      "           2       0.64      0.64      0.64        11\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.72      0.69      0.70        36\n",
      "weighted avg       0.70      0.69      0.70        36\n",
      "\n",
      "******************************The 41 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 3  1  0]\n",
      " [ 3 17  6]\n",
      " [ 1  2  3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.75      0.55         4\n",
      "           1       0.85      0.65      0.74        26\n",
      "           2       0.33      0.50      0.40         6\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.54      0.63      0.56        36\n",
      "weighted avg       0.72      0.64      0.66        36\n",
      "\n",
      "******************************The 42 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 2  1  0]\n",
      " [ 0 20  2]\n",
      " [ 0  7  4]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.71      0.91      0.80        22\n",
      "           2       0.67      0.36      0.47        11\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.79      0.65      0.69        36\n",
      "weighted avg       0.72      0.72      0.70        36\n",
      "\n",
      "******************************The 43 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [ 1 17  6]\n",
      " [ 0  2  7]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       0.89      0.71      0.79        24\n",
      "           2       0.54      0.78      0.64         9\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.73      0.83      0.76        36\n",
      "weighted avg       0.79      0.75      0.76        36\n",
      "\n",
      "******************************The 44 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 4  1  0]\n",
      " [ 2 14  3]\n",
      " [ 0  7  5]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73         5\n",
      "           1       0.64      0.74      0.68        19\n",
      "           2       0.62      0.42      0.50        12\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.64      0.65      0.64        36\n",
      "weighted avg       0.64      0.64      0.63        36\n",
      "\n",
      "******************************The 45 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 5  0  0]\n",
      " [ 3 16  2]\n",
      " [ 1  2  7]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.71         5\n",
      "           1       0.89      0.76      0.82        21\n",
      "           2       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.74      0.82      0.76        36\n",
      "weighted avg       0.81      0.78      0.78        36\n",
      "\n",
      "******************************The 46 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 2  1  0]\n",
      " [ 3 12  6]\n",
      " [ 1  3  8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.67      0.44         3\n",
      "           1       0.75      0.57      0.65        21\n",
      "           2       0.57      0.67      0.62        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.55      0.63      0.57        36\n",
      "weighted avg       0.66      0.61      0.62        36\n",
      "\n",
      "******************************The 47 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 2  1  0]\n",
      " [ 2 15  1]\n",
      " [ 1  4 10]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.67      0.50         3\n",
      "           1       0.75      0.83      0.79        18\n",
      "           2       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.69      0.72      0.69        36\n",
      "weighted avg       0.79      0.75      0.76        36\n",
      "\n",
      "******************************The 48 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 2  1  0]\n",
      " [ 1 14  3]\n",
      " [ 0  4 11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.74      0.78      0.76        18\n",
      "           2       0.79      0.73      0.76        15\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.73      0.73      0.73        36\n",
      "weighted avg       0.75      0.75      0.75        36\n",
      "\n",
      "******************************The 49 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 1  1  0]\n",
      " [ 2 16  2]\n",
      " [ 0  6  8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         2\n",
      "           1       0.70      0.80      0.74        20\n",
      "           2       0.80      0.57      0.67        14\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.61      0.62      0.60        36\n",
      "weighted avg       0.72      0.69      0.69        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random split 10 times, without setting class weights\n",
    "\n",
    "X = fea_df\n",
    "y = label_df.astype(int)\n",
    "\n",
    "for seed in range(40,50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    X_train, y_train = oversample(X_train, y_train, X, y, high_scale=4, low_scale=2) # oversampling\n",
    "\n",
    "    # class_weights = {0: 5, 1: 2, 2: 1}\n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "    y_train = y_train.values.ravel()\n",
    "\n",
    "    # Train the classifier on the resampled training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the original test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'******************************The {seed} seed run*********************************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************The 40 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 2  5  0]\n",
      " [ 0 13  5]\n",
      " [ 0  4  7]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44         7\n",
      "           1       0.59      0.72      0.65        18\n",
      "           2       0.58      0.64      0.61        11\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.72      0.55      0.57        36\n",
      "weighted avg       0.67      0.61      0.60        36\n",
      "\n",
      "******************************The 41 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 3  1  0]\n",
      " [ 2 17  7]\n",
      " [ 1  2  3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.75      0.60         4\n",
      "           1       0.85      0.65      0.74        26\n",
      "           2       0.30      0.50      0.37         6\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.55      0.63      0.57        36\n",
      "weighted avg       0.72      0.64      0.66        36\n",
      "\n",
      "******************************The 42 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 2  1  0]\n",
      " [ 0 19  3]\n",
      " [ 0  6  5]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.73      0.86      0.79        22\n",
      "           2       0.62      0.45      0.53        11\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.79      0.66      0.71        36\n",
      "weighted avg       0.72      0.72      0.71        36\n",
      "\n",
      "******************************The 43 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 3  0  0]\n",
      " [ 0 17  7]\n",
      " [ 0  1  8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       0.94      0.71      0.81        24\n",
      "           2       0.53      0.89      0.67         9\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.83      0.87      0.83        36\n",
      "weighted avg       0.85      0.78      0.79        36\n",
      "\n",
      "******************************The 44 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 3  2  0]\n",
      " [ 1 16  2]\n",
      " [ 0  7  5]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67         5\n",
      "           1       0.64      0.84      0.73        19\n",
      "           2       0.71      0.42      0.53        12\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.70      0.62      0.64        36\n",
      "weighted avg       0.68      0.67      0.65        36\n",
      "\n",
      "******************************The 45 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 2  3  0]\n",
      " [ 1 17  3]\n",
      " [ 1  2  7]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.40      0.44         5\n",
      "           1       0.77      0.81      0.79        21\n",
      "           2       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.66      0.64      0.65        36\n",
      "weighted avg       0.71      0.72      0.72        36\n",
      "\n",
      "******************************The 46 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 1  2  0]\n",
      " [ 0 16  5]\n",
      " [ 1  3  8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.76      0.76      0.76        21\n",
      "           2       0.62      0.67      0.64        12\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.63      0.59      0.60        36\n",
      "weighted avg       0.69      0.69      0.69        36\n",
      "\n",
      "******************************The 47 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 1  2  0]\n",
      " [ 2 14  2]\n",
      " [ 0  4 11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33         3\n",
      "           1       0.70      0.78      0.74        18\n",
      "           2       0.85      0.73      0.79        15\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.63      0.61      0.62        36\n",
      "weighted avg       0.73      0.72      0.72        36\n",
      "\n",
      "******************************The 48 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 2  1  0]\n",
      " [ 0 16  2]\n",
      " [ 0  4 11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.76      0.89      0.82        18\n",
      "           2       0.85      0.73      0.79        15\n",
      "\n",
      "    accuracy                           0.81        36\n",
      "   macro avg       0.87      0.76      0.80        36\n",
      "weighted avg       0.82      0.81      0.80        36\n",
      "\n",
      "******************************The 49 seed run*********************************\n",
      "Confusion Matrix:\n",
      " [[ 1  1  0]\n",
      " [ 1 17  2]\n",
      " [ 0  6  8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         2\n",
      "           1       0.71      0.85      0.77        20\n",
      "           2       0.80      0.57      0.67        14\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.67      0.64      0.65        36\n",
      "weighted avg       0.73      0.72      0.72        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random split 10 times, without setting class weights\n",
    "\n",
    "X = fea_df\n",
    "y = label_df.astype(int)\n",
    "\n",
    "for seed in range(40,50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    X_train, y_train = oversample(X_train, y_train, X, y, high_scale=4, low_scale=0) # oversampling\n",
    "\n",
    "    class_weights = {0: 5, 1: 2, 2: 1}\n",
    "    rf_classifier = RandomForestClassifier(random_state=42, class_weight=class_weights)\n",
    "    y_train = y_train.values.ravel()\n",
    "\n",
    "    # Train the classifier on the resampled training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the original test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f'******************************The {seed} seed run*********************************')\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediciton on Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_df = pd.concat([unimol_repr, sol_repr], axis=1)\n",
    "\n",
    "yields = df['yields'].copy()\n",
    "for i in range(len(yields)):\n",
    "    if yields.iloc[i] == 'low':\n",
    "        yields.iloc[i] = 2\n",
    "    elif yields.iloc[i] == 'medium':\n",
    "        yields.iloc[i] = 1\n",
    "    else:\n",
    "        yields.iloc[i] = 0\n",
    "yields = yields.astype(int)\n",
    "\n",
    "ee = class_label(df['ee'].copy())\n",
    "\n",
    "\n",
    "for i in range(len(ee)):\n",
    "    if ee.iloc[i] == 'low':\n",
    "        ee.iloc[i] = 2\n",
    "    elif ee.iloc[i] == 'medium':\n",
    "        ee.iloc[i] = 1\n",
    "    else:\n",
    "        ee.iloc[i] = 0\n",
    "\n",
    "ee = ee.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 10:07:27 | unimol_tools/models/unimol.py | 146 | INFO | Uni-Mol(QSAR) | Loading pretrained weights from /home/troy/miniconda3/envs/unimol-tool/lib/python3.9/site-packages/unimol_tools-1.0.0-py3.9.egg/unimol_tools/weights/mol_pre_all_h_220816.pt\n",
      "2024-04-25 10:07:27 | unimol_tools/data/conformer.py | 90 | INFO | Uni-Mol(QSAR) | Start generating conformers...\n",
      "1296it [00:11, 110.28it/s]\n",
      "2024-04-25 10:07:39 | unimol_tools/data/conformer.py | 94 | INFO | Uni-Mol(QSAR) | Failed to generate conformers for 0.00% of molecules.\n",
      "2024-04-25 10:07:39 | unimol_tools/data/conformer.py | 96 | INFO | Uni-Mol(QSAR) | Failed to generate 3d conformers for 0.00% of molecules.\n",
      "100%|██████████| 41/41 [00:29<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.187755</td>\n",
       "      <td>-0.757094</td>\n",
       "      <td>-0.230801</td>\n",
       "      <td>-0.263155</td>\n",
       "      <td>-0.378224</td>\n",
       "      <td>-1.489209</td>\n",
       "      <td>0.830283</td>\n",
       "      <td>0.751223</td>\n",
       "      <td>-0.411963</td>\n",
       "      <td>1.606491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975573</td>\n",
       "      <td>0.280888</td>\n",
       "      <td>0.151558</td>\n",
       "      <td>-2.630810</td>\n",
       "      <td>1.290600</td>\n",
       "      <td>0.540199</td>\n",
       "      <td>-0.783475</td>\n",
       "      <td>2.103269</td>\n",
       "      <td>0.628125</td>\n",
       "      <td>-2.140517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.147666</td>\n",
       "      <td>-0.721462</td>\n",
       "      <td>-0.427698</td>\n",
       "      <td>-0.452070</td>\n",
       "      <td>-0.341001</td>\n",
       "      <td>-1.340670</td>\n",
       "      <td>0.710630</td>\n",
       "      <td>0.798275</td>\n",
       "      <td>-0.462686</td>\n",
       "      <td>1.552800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992516</td>\n",
       "      <td>0.208612</td>\n",
       "      <td>0.193683</td>\n",
       "      <td>-2.656662</td>\n",
       "      <td>1.284773</td>\n",
       "      <td>0.515903</td>\n",
       "      <td>-0.736329</td>\n",
       "      <td>2.127645</td>\n",
       "      <td>0.620427</td>\n",
       "      <td>-2.132180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.112590</td>\n",
       "      <td>-0.782315</td>\n",
       "      <td>0.031480</td>\n",
       "      <td>-0.393942</td>\n",
       "      <td>-0.552017</td>\n",
       "      <td>-1.477100</td>\n",
       "      <td>0.822358</td>\n",
       "      <td>0.815920</td>\n",
       "      <td>-0.622068</td>\n",
       "      <td>1.670280</td>\n",
       "      <td>...</td>\n",
       "      <td>1.192423</td>\n",
       "      <td>0.282513</td>\n",
       "      <td>0.102725</td>\n",
       "      <td>-2.643875</td>\n",
       "      <td>1.256638</td>\n",
       "      <td>0.515042</td>\n",
       "      <td>-0.887655</td>\n",
       "      <td>2.158556</td>\n",
       "      <td>0.722484</td>\n",
       "      <td>-2.132981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.195905</td>\n",
       "      <td>-0.708368</td>\n",
       "      <td>-0.438068</td>\n",
       "      <td>-0.039942</td>\n",
       "      <td>-0.576910</td>\n",
       "      <td>-2.054896</td>\n",
       "      <td>0.743676</td>\n",
       "      <td>0.733531</td>\n",
       "      <td>-0.591675</td>\n",
       "      <td>1.497057</td>\n",
       "      <td>...</td>\n",
       "      <td>1.008958</td>\n",
       "      <td>0.267344</td>\n",
       "      <td>0.132643</td>\n",
       "      <td>-2.577739</td>\n",
       "      <td>1.266693</td>\n",
       "      <td>0.442742</td>\n",
       "      <td>-0.628048</td>\n",
       "      <td>2.121150</td>\n",
       "      <td>0.302955</td>\n",
       "      <td>-2.106254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.252859</td>\n",
       "      <td>-0.642398</td>\n",
       "      <td>-0.366567</td>\n",
       "      <td>-0.161933</td>\n",
       "      <td>-0.604376</td>\n",
       "      <td>-1.946272</td>\n",
       "      <td>0.809062</td>\n",
       "      <td>0.753072</td>\n",
       "      <td>-0.668638</td>\n",
       "      <td>1.584506</td>\n",
       "      <td>...</td>\n",
       "      <td>1.106878</td>\n",
       "      <td>0.349753</td>\n",
       "      <td>0.110153</td>\n",
       "      <td>-2.584254</td>\n",
       "      <td>1.268440</td>\n",
       "      <td>0.510725</td>\n",
       "      <td>-0.682220</td>\n",
       "      <td>2.122981</td>\n",
       "      <td>0.447711</td>\n",
       "      <td>-2.095988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>-0.251603</td>\n",
       "      <td>-0.666749</td>\n",
       "      <td>-0.353784</td>\n",
       "      <td>-0.113625</td>\n",
       "      <td>-0.695911</td>\n",
       "      <td>-1.973817</td>\n",
       "      <td>0.884866</td>\n",
       "      <td>0.887493</td>\n",
       "      <td>-0.557792</td>\n",
       "      <td>1.553054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.481325</td>\n",
       "      <td>0.153730</td>\n",
       "      <td>-2.653371</td>\n",
       "      <td>1.296592</td>\n",
       "      <td>0.352911</td>\n",
       "      <td>-0.581045</td>\n",
       "      <td>2.229146</td>\n",
       "      <td>0.502051</td>\n",
       "      <td>-2.088052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>-0.256360</td>\n",
       "      <td>-0.853312</td>\n",
       "      <td>-0.156872</td>\n",
       "      <td>-0.193501</td>\n",
       "      <td>-0.632463</td>\n",
       "      <td>-1.576671</td>\n",
       "      <td>0.971514</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>-0.584494</td>\n",
       "      <td>1.470471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>0.626916</td>\n",
       "      <td>0.139105</td>\n",
       "      <td>-2.687439</td>\n",
       "      <td>1.343616</td>\n",
       "      <td>0.418711</td>\n",
       "      <td>-0.539786</td>\n",
       "      <td>2.281996</td>\n",
       "      <td>0.935813</td>\n",
       "      <td>-2.075972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>-0.167522</td>\n",
       "      <td>-0.795294</td>\n",
       "      <td>-0.521734</td>\n",
       "      <td>0.089814</td>\n",
       "      <td>-0.657123</td>\n",
       "      <td>-2.063783</td>\n",
       "      <td>0.897399</td>\n",
       "      <td>0.927285</td>\n",
       "      <td>-0.476006</td>\n",
       "      <td>1.265823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859283</td>\n",
       "      <td>0.344413</td>\n",
       "      <td>0.174654</td>\n",
       "      <td>-2.592965</td>\n",
       "      <td>1.277332</td>\n",
       "      <td>0.410306</td>\n",
       "      <td>-0.425973</td>\n",
       "      <td>2.205443</td>\n",
       "      <td>0.385370</td>\n",
       "      <td>-2.108131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>-0.187342</td>\n",
       "      <td>-0.751482</td>\n",
       "      <td>-0.416212</td>\n",
       "      <td>-0.010506</td>\n",
       "      <td>-0.699113</td>\n",
       "      <td>-2.133993</td>\n",
       "      <td>0.851930</td>\n",
       "      <td>0.911150</td>\n",
       "      <td>-0.507752</td>\n",
       "      <td>1.368326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855938</td>\n",
       "      <td>0.395879</td>\n",
       "      <td>0.205777</td>\n",
       "      <td>-2.620315</td>\n",
       "      <td>1.279013</td>\n",
       "      <td>0.320983</td>\n",
       "      <td>-0.544632</td>\n",
       "      <td>2.227513</td>\n",
       "      <td>0.447895</td>\n",
       "      <td>-2.109630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>-0.262351</td>\n",
       "      <td>-0.684898</td>\n",
       "      <td>-0.272117</td>\n",
       "      <td>-0.132105</td>\n",
       "      <td>-0.655059</td>\n",
       "      <td>-1.939248</td>\n",
       "      <td>0.909707</td>\n",
       "      <td>0.882733</td>\n",
       "      <td>-0.539081</td>\n",
       "      <td>1.531860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803758</td>\n",
       "      <td>0.599700</td>\n",
       "      <td>0.260548</td>\n",
       "      <td>-2.671783</td>\n",
       "      <td>1.294751</td>\n",
       "      <td>0.417493</td>\n",
       "      <td>-0.438113</td>\n",
       "      <td>2.260753</td>\n",
       "      <td>0.586037</td>\n",
       "      <td>-2.084597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.187755 -0.757094 -0.230801 -0.263155 -0.378224 -1.489209  0.830283   \n",
       "1    -0.147666 -0.721462 -0.427698 -0.452070 -0.341001 -1.340670  0.710630   \n",
       "2    -0.112590 -0.782315  0.031480 -0.393942 -0.552017 -1.477100  0.822358   \n",
       "3    -0.195905 -0.708368 -0.438068 -0.039942 -0.576910 -2.054896  0.743676   \n",
       "4    -0.252859 -0.642398 -0.366567 -0.161933 -0.604376 -1.946272  0.809062   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1291 -0.251603 -0.666749 -0.353784 -0.113625 -0.695911 -1.973817  0.884866   \n",
       "1292 -0.256360 -0.853312 -0.156872 -0.193501 -0.632463 -1.576671  0.971514   \n",
       "1293 -0.167522 -0.795294 -0.521734  0.089814 -0.657123 -2.063783  0.897399   \n",
       "1294 -0.187342 -0.751482 -0.416212 -0.010506 -0.699113 -2.133993  0.851930   \n",
       "1295 -0.262351 -0.684898 -0.272117 -0.132105 -0.655059 -1.939248  0.909707   \n",
       "\n",
       "           7         8         9    ...       502       503       504  \\\n",
       "0     0.751223 -0.411963  1.606491  ...  0.975573  0.280888  0.151558   \n",
       "1     0.798275 -0.462686  1.552800  ...  0.992516  0.208612  0.193683   \n",
       "2     0.815920 -0.622068  1.670280  ...  1.192423  0.282513  0.102725   \n",
       "3     0.733531 -0.591675  1.497057  ...  1.008958  0.267344  0.132643   \n",
       "4     0.753072 -0.668638  1.584506  ...  1.106878  0.349753  0.110153   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1291  0.887493 -0.557792  1.553054  ...  0.825795  0.481325  0.153730   \n",
       "1292  0.999443 -0.584494  1.470471  ...  0.798278  0.626916  0.139105   \n",
       "1293  0.927285 -0.476006  1.265823  ...  0.859283  0.344413  0.174654   \n",
       "1294  0.911150 -0.507752  1.368326  ...  0.855938  0.395879  0.205777   \n",
       "1295  0.882733 -0.539081  1.531860  ...  0.803758  0.599700  0.260548   \n",
       "\n",
       "           505       506       507       508       509       510       511  \n",
       "0    -2.630810  1.290600  0.540199 -0.783475  2.103269  0.628125 -2.140517  \n",
       "1    -2.656662  1.284773  0.515903 -0.736329  2.127645  0.620427 -2.132180  \n",
       "2    -2.643875  1.256638  0.515042 -0.887655  2.158556  0.722484 -2.132981  \n",
       "3    -2.577739  1.266693  0.442742 -0.628048  2.121150  0.302955 -2.106254  \n",
       "4    -2.584254  1.268440  0.510725 -0.682220  2.122981  0.447711 -2.095988  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1291 -2.653371  1.296592  0.352911 -0.581045  2.229146  0.502051 -2.088052  \n",
       "1292 -2.687439  1.343616  0.418711 -0.539786  2.281996  0.935813 -2.075972  \n",
       "1293 -2.592965  1.277332  0.410306 -0.425973  2.205443  0.385370 -2.108131  \n",
       "1294 -2.620315  1.279013  0.320983 -0.544632  2.227513  0.447895 -2.109630  \n",
       "1295 -2.671783  1.294751  0.417493 -0.438113  2.260753  0.586037 -2.084597  \n",
       "\n",
       "[1296 rows x 512 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load library\n",
    "seq_lib = pd.read_csv('./1296seq_to_test.csv')\n",
    "\n",
    "# Insert SMILES column\n",
    "seq_lib.insert(1, column='pep_smiles', value='')\n",
    "for i in seq_lib.index.tolist():\n",
    "    seq_lib.iloc[i,1] = utils.pep_seq_transform(seq_lib.iloc[i,0])\n",
    "# Generate UniMol Representations of peptides\n",
    "clf = UniMolRepr(data_type='molecule')\n",
    "smi_list = seq_lib['pep_smiles'].values.tolist()\n",
    "unimol_repr = clf.get_repr(smi_list, return_atomic_reprs=False)\n",
    "# CLS token repr\n",
    "print(np.array(unimol_repr['cls_repr']).shape)\n",
    "\n",
    "pep_repr = pd.DataFrame(np.array(unimol_repr['cls_repr']))\n",
    "# pep_repr = pd.read_csv('../Unimol_model/cluster/results_VPGLA/VPGLA_feature.csv',header=None)\n",
    "\n",
    "pep_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.046752</td>\n",
       "      <td>-0.654765</td>\n",
       "      <td>-0.624287</td>\n",
       "      <td>-0.709546</td>\n",
       "      <td>0.241607</td>\n",
       "      <td>-1.19603</td>\n",
       "      <td>1.033706</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>-1.105541</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.588123</td>\n",
       "      <td>-2.801194</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>-0.392907</td>\n",
       "      <td>0.52999</td>\n",
       "      <td>2.377182</td>\n",
       "      <td>0.318138</td>\n",
       "      <td>-1.967838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.046752</td>\n",
       "      <td>-0.654765</td>\n",
       "      <td>-0.624287</td>\n",
       "      <td>-0.709546</td>\n",
       "      <td>0.241607</td>\n",
       "      <td>-1.19603</td>\n",
       "      <td>1.033706</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>-1.105541</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.588123</td>\n",
       "      <td>-2.801194</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>-0.392907</td>\n",
       "      <td>0.52999</td>\n",
       "      <td>2.377182</td>\n",
       "      <td>0.318138</td>\n",
       "      <td>-1.967838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.046752</td>\n",
       "      <td>-0.654765</td>\n",
       "      <td>-0.624287</td>\n",
       "      <td>-0.709546</td>\n",
       "      <td>0.241607</td>\n",
       "      <td>-1.19603</td>\n",
       "      <td>1.033706</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>-1.105541</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.588123</td>\n",
       "      <td>-2.801194</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>-0.392907</td>\n",
       "      <td>0.52999</td>\n",
       "      <td>2.377182</td>\n",
       "      <td>0.318138</td>\n",
       "      <td>-1.967838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.046752</td>\n",
       "      <td>-0.654765</td>\n",
       "      <td>-0.624287</td>\n",
       "      <td>-0.709546</td>\n",
       "      <td>0.241607</td>\n",
       "      <td>-1.19603</td>\n",
       "      <td>1.033706</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>-1.105541</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.588123</td>\n",
       "      <td>-2.801194</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>-0.392907</td>\n",
       "      <td>0.52999</td>\n",
       "      <td>2.377182</td>\n",
       "      <td>0.318138</td>\n",
       "      <td>-1.967838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046752</td>\n",
       "      <td>-0.654765</td>\n",
       "      <td>-0.624287</td>\n",
       "      <td>-0.709546</td>\n",
       "      <td>0.241607</td>\n",
       "      <td>-1.19603</td>\n",
       "      <td>1.033706</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>-1.105541</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.588123</td>\n",
       "      <td>-2.801194</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>-0.392907</td>\n",
       "      <td>0.52999</td>\n",
       "      <td>2.377182</td>\n",
       "      <td>0.318138</td>\n",
       "      <td>-1.967838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1.046752</td>\n",
       "      <td>-0.654765</td>\n",
       "      <td>-0.624287</td>\n",
       "      <td>-0.709546</td>\n",
       "      <td>0.241607</td>\n",
       "      <td>-1.19603</td>\n",
       "      <td>1.033706</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>-1.105541</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.588123</td>\n",
       "      <td>-2.801194</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>-0.392907</td>\n",
       "      <td>0.52999</td>\n",
       "      <td>2.377182</td>\n",
       "      <td>0.318138</td>\n",
       "      <td>-1.967838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1.046752</td>\n",
       "      <td>-0.654765</td>\n",
       "      <td>-0.624287</td>\n",
       "      <td>-0.709546</td>\n",
       "      <td>0.241607</td>\n",
       "      <td>-1.19603</td>\n",
       "      <td>1.033706</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>-1.105541</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.588123</td>\n",
       "      <td>-2.801194</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>-0.392907</td>\n",
       "      <td>0.52999</td>\n",
       "      <td>2.377182</td>\n",
       "      <td>0.318138</td>\n",
       "      <td>-1.967838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1.046752</td>\n",
       "      <td>-0.654765</td>\n",
       "      <td>-0.624287</td>\n",
       "      <td>-0.709546</td>\n",
       "      <td>0.241607</td>\n",
       "      <td>-1.19603</td>\n",
       "      <td>1.033706</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>-1.105541</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.588123</td>\n",
       "      <td>-2.801194</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>-0.392907</td>\n",
       "      <td>0.52999</td>\n",
       "      <td>2.377182</td>\n",
       "      <td>0.318138</td>\n",
       "      <td>-1.967838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1.046752</td>\n",
       "      <td>-0.654765</td>\n",
       "      <td>-0.624287</td>\n",
       "      <td>-0.709546</td>\n",
       "      <td>0.241607</td>\n",
       "      <td>-1.19603</td>\n",
       "      <td>1.033706</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>-1.105541</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.588123</td>\n",
       "      <td>-2.801194</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>-0.392907</td>\n",
       "      <td>0.52999</td>\n",
       "      <td>2.377182</td>\n",
       "      <td>0.318138</td>\n",
       "      <td>-1.967838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1.046752</td>\n",
       "      <td>-0.654765</td>\n",
       "      <td>-0.624287</td>\n",
       "      <td>-0.709546</td>\n",
       "      <td>0.241607</td>\n",
       "      <td>-1.19603</td>\n",
       "      <td>1.033706</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>-1.105541</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.588123</td>\n",
       "      <td>-2.801194</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>-0.392907</td>\n",
       "      <td>0.52999</td>\n",
       "      <td>2.377182</td>\n",
       "      <td>0.318138</td>\n",
       "      <td>-1.967838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4        5         6  \\\n",
       "0     1.046752 -0.654765 -0.624287 -0.709546  0.241607 -1.19603  1.033706   \n",
       "1     1.046752 -0.654765 -0.624287 -0.709546  0.241607 -1.19603  1.033706   \n",
       "2     1.046752 -0.654765 -0.624287 -0.709546  0.241607 -1.19603  1.033706   \n",
       "3     1.046752 -0.654765 -0.624287 -0.709546  0.241607 -1.19603  1.033706   \n",
       "4     1.046752 -0.654765 -0.624287 -0.709546  0.241607 -1.19603  1.033706   \n",
       "...        ...       ...       ...       ...       ...      ...       ...   \n",
       "1291  1.046752 -0.654765 -0.624287 -0.709546  0.241607 -1.19603  1.033706   \n",
       "1292  1.046752 -0.654765 -0.624287 -0.709546  0.241607 -1.19603  1.033706   \n",
       "1293  1.046752 -0.654765 -0.624287 -0.709546  0.241607 -1.19603  1.033706   \n",
       "1294  1.046752 -0.654765 -0.624287 -0.709546  0.241607 -1.19603  1.033706   \n",
       "1295  1.046752 -0.654765 -0.624287 -0.709546  0.241607 -1.19603  1.033706   \n",
       "\n",
       "             7         8         9  ...       502       503       504  \\\n",
       "0     0.971329 -1.105541  0.868621  ... -0.032768  0.499183  0.588123   \n",
       "1     0.971329 -1.105541  0.868621  ... -0.032768  0.499183  0.588123   \n",
       "2     0.971329 -1.105541  0.868621  ... -0.032768  0.499183  0.588123   \n",
       "3     0.971329 -1.105541  0.868621  ... -0.032768  0.499183  0.588123   \n",
       "4     0.971329 -1.105541  0.868621  ... -0.032768  0.499183  0.588123   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1291  0.971329 -1.105541  0.868621  ... -0.032768  0.499183  0.588123   \n",
       "1292  0.971329 -1.105541  0.868621  ... -0.032768  0.499183  0.588123   \n",
       "1293  0.971329 -1.105541  0.868621  ... -0.032768  0.499183  0.588123   \n",
       "1294  0.971329 -1.105541  0.868621  ... -0.032768  0.499183  0.588123   \n",
       "1295  0.971329 -1.105541  0.868621  ... -0.032768  0.499183  0.588123   \n",
       "\n",
       "           505       506       507      508       509       510       511  \n",
       "0    -2.801194  0.802723 -0.392907  0.52999  2.377182  0.318138 -1.967838  \n",
       "1    -2.801194  0.802723 -0.392907  0.52999  2.377182  0.318138 -1.967838  \n",
       "2    -2.801194  0.802723 -0.392907  0.52999  2.377182  0.318138 -1.967838  \n",
       "3    -2.801194  0.802723 -0.392907  0.52999  2.377182  0.318138 -1.967838  \n",
       "4    -2.801194  0.802723 -0.392907  0.52999  2.377182  0.318138 -1.967838  \n",
       "...        ...       ...       ...      ...       ...       ...       ...  \n",
       "1291 -2.801194  0.802723 -0.392907  0.52999  2.377182  0.318138 -1.967838  \n",
       "1292 -2.801194  0.802723 -0.392907  0.52999  2.377182  0.318138 -1.967838  \n",
       "1293 -2.801194  0.802723 -0.392907  0.52999  2.377182  0.318138 -1.967838  \n",
       "1294 -2.801194  0.802723 -0.392907  0.52999  2.377182  0.318138 -1.967838  \n",
       "1295 -2.801194  0.802723 -0.392907  0.52999  2.377182  0.318138 -1.967838  \n",
       "\n",
       "[1296 rows x 512 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dce_repr = sol_repr.iloc[4].copy()\n",
    "dce_df = pd.DataFrame([dce_repr] * 1296, index=range(1296),columns=sol_repr.columns)\n",
    "dce_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fea_df\n",
    "x_test  = pd.concat([pep_repr,dce_df],axis=1)\n",
    "x_test.columns = x_test.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0: 3, 1: 2, 2: 1}\n",
    "yield_classifier = RandomForestClassifier(random_state=42, class_weight= class_weights) #\n",
    "yield_train, yields = oversample(X_train, yields, X_train, yields, high_scale=8, medium_scale=4) \n",
    "yield_classifier.fit(yield_train, yields)\n",
    "yield_pred = yield_classifier.predict(x_test)\n",
    "seq_lib.insert(3,'yield_pred', yield_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0: 4, 1: 2, 2: 1}\n",
    "ee_classifier = RandomForestClassifier(random_state=42, class_weight= class_weights)\n",
    "ee_train, ee = oversample(X_train, ee, X_train, ee, high_scale=2, low_scale=1) \n",
    "ee_classifier.fit(ee_train, ee)\n",
    "ee_pred = ee_classifier.predict(x_test)\n",
    "\n",
    "seq_lib.insert(4,'ee_pred', ee_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lib.to_csv('./Pred/Trained_on_180_oversample_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
