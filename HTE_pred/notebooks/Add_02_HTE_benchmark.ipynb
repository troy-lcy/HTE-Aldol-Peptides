{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark different featurization on 3 HTE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "df_19 = pd.read_csv('data/19_science/19_science_total.csv', )\n",
    "df_18 = pd.read_excel('data/18_science/18 science_original_chem.xlsx')\n",
    "df_sm = pd.read_excel(\"data/suzuki/suzuki.xlsx\").dropna().reset_index(drop=True)\n",
    "df_pep = pd.read_csv('data/peptide_data/conjugate_addition.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE19:(1075, 53), OHE18:(3955, 44), OHE_sm:(4620, 33), OHE_pep:(200, 55)\n",
      "Catalyst_smi_MACCS.csv的维度: (1075, 167)\n",
      "Imine_smi_MACCS.csv的维度: (1075, 167)\n",
      "MACCS.csv的维度: (5, 167)\n",
      "Thiol_smi_MACCS.csv的维度: (1075, 167)\n",
      "合并后的维度: (1075, 668)\n",
      "Additive_MACCS.csv的维度: (3955, 167)\n",
      "Aryl halide_MACCS.csv的维度: (3955, 167)\n",
      "Base_MACCS.csv的维度: (3955, 167)\n",
      "Ligand_MACCS.csv的维度: (3955, 167)\n",
      "合并后的维度: (3955, 668)\n",
      "ligand_fingerprints.csv的维度: (4620, 167)\n",
      "reactant_1_fingerprints.csv的维度: (4620, 167)\n",
      "reactant_2_fingerprints.csv的维度: (4620, 167)\n",
      "reagent_1_fingerprints.csv的维度: (4620, 167)\n",
      "solvent_1_fingerprints.csv的维度: (4620, 167)\n",
      "合并后的维度: (4620, 835)\n",
      "peptide_SMILES_MACCS.csv的维度: (200, 167)\n",
      "Reactant_1_smi_MACCS.csv的维度: (200, 167)\n",
      "Reactant_2_smi_MACCS.csv的维度: (200, 167)\n",
      "合并后的维度: (200, 501)\n",
      "Catalyst_smi_descriptors.csv的维度: (1075, 209)\n",
      "Imine_smi_descriptors.csv的维度: (1075, 209)\n",
      "Thiol_smi_descriptors.csv的维度: (1075, 209)\n",
      "合并后的维度: (1075, 627)\n",
      "Additive_descriptors.csv的维度: (3955, 209)\n",
      "Aryl halide_descriptors.csv的维度: (3955, 209)\n",
      "Base_descriptors.csv的维度: (3955, 209)\n",
      "Ligand_descriptors.csv的维度: (3955, 209)\n",
      "合并后的维度: (3955, 836)\n",
      "ligand_descriptors.csv的维度: (4620, 209)\n",
      "reactant_1_descriptors.csv的维度: (4620, 209)\n",
      "reactant_2_descriptors.csv的维度: (4620, 209)\n",
      "reagent_1_descriptors.csv的维度: (4620, 209)\n",
      "solvent_1_descriptors.csv的维度: (4620, 209)\n",
      "合并后的维度: (4620, 1045)\n",
      "peptide_SMILES_descriptors.csv的维度: (50, 209)\n",
      "Reactant_1_smi_descriptors.csv的维度: (2, 209)\n",
      "Reactant_2_smi_descriptors.csv的维度: (3, 209)\n",
      "合并后的维度: (50, 627)\n",
      "Catalyst_1421.csv的维度: (1075, 1421)\n",
      "Imine_1435.csv的维度: (1075, 1435)\n",
      "Thiol_(1075, 1223).csv的维度: (1075, 1223)\n",
      "合并后的维度: (1075, 4079)\n",
      "Additive_(3955, 1282).csv的维度: (3955, 1282)\n",
      "Aryl halide_(3955, 1282).csv的维度: (3955, 1282)\n",
      "Base_(3955, 1377).csv的维度: (3955, 1377)\n",
      "Ligand_(3955, 1436).csv的维度: (3955, 1436)\n",
      "合并后的维度: (3955, 5377)\n",
      "Ligand_(4620, 1065).csv的维度: (4620, 1065)\n",
      "reactant_1_(4620, 1164).csv的维度: (4620, 1164)\n",
      "reactant_2_(4620, 1177).csv的维度: (4620, 1177)\n",
      "reagent_1_(4620, 783).csv的维度: (4620, 783)\n",
      "solvent_1_(4620, 927).csv的维度: (4620, 927)\n",
      "合并后的维度: (4620, 5116)\n",
      "peptide_SMILES_mordred.csv的维度: (200, 1435)\n",
      "Reactant_1_smi_mordred.csv的维度: (200, 1234)\n",
      "Reactant_2_smi_mordred.csv的维度: (200, 1433)\n",
      "合并后的维度: (200, 4102)\n",
      "Catalyst_smirepr.csv的维度: (1075, 512)\n",
      "Imine_smirepr.csv的维度: (1075, 512)\n",
      "Thiol_smirepr.csv的维度: (1075, 512)\n",
      "合并后的维度: (1075, 1536)\n",
      "Additiverepr.csv的维度: (3955, 512)\n",
      "Aryl haliderepr.csv的维度: (3955, 512)\n",
      "Baserepr.csv的维度: (3955, 512)\n",
      "Ligandrepr.csv的维度: (3955, 512)\n",
      "合并后的维度: (3955, 2048)\n",
      "ligandrepr.csv的维度: (4620, 512)\n",
      "reactant_1repr.csv的维度: (4620, 512)\n",
      "reactant_2repr.csv的维度: (4620, 512)\n",
      "reagent_1repr.csv的维度: (4620, 512)\n",
      "solvent_1repr.csv的维度: (4620, 512)\n",
      "合并后的维度: (4620, 2560)\n",
      "tripeptidespeptide_SMILES.csv的维度: (200, 512)\n",
      "tripeptidesReactant_1_smi.csv的维度: (200, 512)\n",
      "tripeptidesReactant_2_smi.csv的维度: (200, 512)\n",
      "合并后的维度: (200, 1536)\n"
     ]
    }
   ],
   "source": [
    "# read descriptor\n",
    "des_path = 'HTE_descriptors'\n",
    "\n",
    "def read_des(folder='folder_name'):\n",
    "    # folder = 'MFP_descriptor'\n",
    "    file_list = [f for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "    # 读取并处理每个文件\n",
    "    fp_dfs = []\n",
    "    for filename in file_list:\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        if 'Original_SMILES' in df.columns:\n",
    "            df = df.drop(columns=['Original_SMILES'])\n",
    "    \n",
    "        # 使用文件名作为前缀（去掉扩展名）\n",
    "        prefix = os.path.splitext(filename)[0]\n",
    "        df.columns = [f\"{prefix}_{col}\" for col in df.columns]\n",
    "        print(f\"{filename}的维度:\", df.shape)\n",
    "        fp_dfs.append(df)\n",
    "\n",
    "    # 合并所有分子指纹特征\n",
    "    combined_fp = pd.concat(fp_dfs, axis=1)\n",
    "    # 输出结果查看\n",
    "    print(\"合并后的维度:\", combined_fp.shape)\n",
    "    return combined_fp\n",
    "\n",
    "# one-hot encode\n",
    "OHE_19 = pd.read_csv(os.path.join(des_path, f\"OH_encode/19_onehot.csv\"))\n",
    "OHE_18 = pd.read_csv(os.path.join(des_path, f\"OH_encode/18_onehot.csv\"))\n",
    "OHE_sm = pd.read_csv(os.path.join(des_path, f\"OH_encode/sm_onehot.csv\"))\n",
    "OHE_pep = pd.read_csv(os.path.join(des_path, f\"OH_encode/conjugate_onehot.csv\"))\n",
    "\n",
    "print(f\"OHE19:{OHE_19.shape}, OHE18:{OHE_18.shape}, OHE_sm:{OHE_sm.shape}, OHE_pep:{OHE_pep.shape}\")\n",
    "\n",
    "# 分子指纹（Morgan Fingerprint）\n",
    "\n",
    "# FP_19 = read_des(os.path.join(des_path, 'MFP_descriptor/19_data'))\n",
    "# FP_18 = read_des(os.path.join(des_path, 'MFP_descriptor/18_data'))\n",
    "# FP_sm = read_des(os.path.join(des_path, 'MFP_descriptor/suzuki'))\n",
    "FP_19 = read_des(os.path.join(des_path, 'MACCS/19_data'))\n",
    "FP_18 = read_des(os.path.join(des_path, 'MACCS/18_data'))\n",
    "FP_sm = read_des(os.path.join(des_path, 'MACCS/suzuki'))\n",
    "FP_pep = read_des(os.path.join(des_path, 'MACCS/conjugate'))\n",
    "\n",
    "\n",
    "# RDKit 分子性质\n",
    "\n",
    "RDkit_19 = read_des(os.path.join(des_path, 'RDKit_descriptors/19_data'))\n",
    "RDKit_18 = read_des(os.path.join(des_path, 'RDKit_descriptors/18_data'))\n",
    "RDkit_sm = read_des(os.path.join(des_path, 'RDKit_descriptors/suzuki'))\n",
    "RDkit_sm = read_des(os.path.join(des_path, 'RDKit_descriptors/conjugate'))\n",
    "\n",
    "# mordred\n",
    "Mord_19 = read_des(os.path.join(des_path, 'Mordred/19_data'))\n",
    "Mord_18 = read_des(os.path.join(des_path, 'Mordred/18_data'))\n",
    "Mord_sm = read_des(os.path.join(des_path, 'Mordred/suzuki'))\n",
    "Mord_pep = read_des(os.path.join(des_path, 'Mordred/conjugate'))\n",
    "\n",
    "UniMol_19 = read_des(os.path.join(des_path, 'unimol/19_data'))\n",
    "UniMol_18 = read_des(os.path.join(des_path, 'unimol/18_data'))\n",
    "UniMol_sm = read_des(os.path.join(des_path, 'unimol/suzuki'))\n",
    "UniMol_pep = read_des(os.path.join(des_path, 'unimol/conjugate'))\n",
    "\n",
    "# X_desc = rdkit_descriptors(df['full_smi'])\n",
    "# desc_dim = X_desc.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 清理 RDKit 特征数据\n",
    "def clean_rdkit_features(X):\n",
    "    imp = SimpleImputer(strategy='mean')\n",
    "    scaler = StandardScaler()\n",
    "    X_clean = imp.fit_transform(X)\n",
    "    X_scaled = scaler.fit_transform(X_clean)\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from mordred import Calculator, descriptors\n",
    "\n",
    "# 初始化 Mordred 描述符计算器\n",
    "calc = Calculator(descriptors, ignore_3D=True)\n",
    "\n",
    "# 示例 SMILES（替换为你自己的）\n",
    "smiles_list = [\n",
    "    \"CC(C)O\", \n",
    "    \"c1ccccc1\", \n",
    "    \"C1CCCCC1\", \n",
    "    \"CC(=O)O\", \n",
    "    \"INVALID_SMILES\"\n",
    "]\n",
    "\n",
    "# 过滤非法 SMILES\n",
    "mols = []\n",
    "valid_indices = []\n",
    "for i, smi in enumerate(smiles_list):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        mols.append(mol)\n",
    "        valid_indices.append(i)\n",
    "\n",
    "# 计算描述符\n",
    "df = calc.pandas(mols)\n",
    "\n",
    "# 替换 inf 为 NaN，删除含 NaN 的列\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna(axis=1, how='any')\n",
    "\n",
    "# 删除包含非数字（例如字符）的列\n",
    "def is_column_all_numeric(col):\n",
    "    try:\n",
    "        return col.apply(lambda x: isinstance(x, (int, float, np.integer, np.floating))).all()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "numeric_cols = [col for col in df.columns if is_column_all_numeric(df[col])]\n",
    "df_cleaned = df[numeric_cols]\n",
    "\n",
    "# 添加 SMILES 列（可选）\n",
    "df_cleaned['Original_SMILES'] = [smiles_list[i] for i in valid_indices]\n",
    "\n",
    "# 查看结果\n",
    "print(\"最终维度（所有值为纯数值）:\", df_cleaned.shape)\n",
    "\n",
    "# 保存\n",
    "df_cleaned.to_csv('final_clean_mordred_descriptors.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, model_type=\"MLP\", n_runs=30):\n",
    "    r2_scores, maes, times = [], [], []\n",
    "\n",
    "    for _ in tqdm(range(n_runs)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "        if model_type == \"MLP\":\n",
    "            model = MLPRegressor(hidden_layer_sizes=(256, 128), activation='relu',\n",
    "                                 solver='adam', alpha=1e-4, max_iter=1000, random_state=0)\n",
    "        elif model_type == \"RF\":\n",
    "            model = RandomForestRegressor(n_estimators=300,max_depth=15, random_state=42, n_jobs=-1) # , min_samples_split=5\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model.\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        r2_scores.append(r2_score(y_test, y_pred))\n",
    "        maes.append(mean_absolute_error(y_test, y_pred))\n",
    "        times.append(duration)\n",
    "\n",
    "        # model.fit(X_train, y_train)\n",
    "        # y_pred = model.predict(X_test)\n",
    "        # r2_scores.append(r2_score(y_test, y_pred))\n",
    "        # maes.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "    return {\n",
    "        'R2_mean': np.mean(r2_scores),\n",
    "        'R2_std': np.std(r2_scores),\n",
    "        'MAE_mean': np.mean(maes),\n",
    "        'MAE_std': np.std(maes),\n",
    "        'Time_mean': np.mean(times),\n",
    "        'Time_std': np.std(times)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:21<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature_Type Model  Dim   R2_mean    R2_std  MAE_mean   MAE_std\n",
      "0       Unimol    RF  100  0.907735  0.012775  0.144409  0.008373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "#运行对比 只使用随机森林模型\n",
    "# load data without pca\n",
    "# X_onehot = OHE_19\n",
    "# X_fp = FP_19.fillna(0)\n",
    "# X_desc = RDkit_19\n",
    "# X_mord = Mord_19\n",
    "\n",
    "# load data with pca\n",
    "pca = PCA(n_components=100)\n",
    "X_fp = pca.fit_transform(FP_19.fillna(0))\n",
    "X_desc = pca.fit_transform(RDkit_19)\n",
    "X_mord = pca.fit_transform(Mord_19)\n",
    "X_unimol = pca.fit_transform(UniMol_19)\n",
    "\n",
    "y = df_19['Output'].values\n",
    "\n",
    "# 1 test on 19 science data\n",
    "for X, name, dim in [\n",
    "    # # (X_onehot, \"OneHot_SMILES\", X_onehot.shape[1]),\n",
    "    # (X_fp, \"Fingerprint\", X_fp.shape[1]),\n",
    "    # (clean_rdkit_features(X_desc), \"RDKit_Descriptors\", X_desc.shape[1]),\n",
    "    # (X_mord, \"Mordred\", X_mord.shape[1]),\n",
    "    (X_unimol,\"Unimol\",X_unimol.shape[1])\n",
    "]:\n",
    "    for model in [\"RF\"]:\n",
    "        result = evaluate_model(X, y, model_type=model, n_runs=30)\n",
    "        results.append([name, model, dim,\n",
    "                        result['R2_mean'], result['R2_std'],\n",
    "                        result['MAE_mean'], result['MAE_std']])\n",
    "\n",
    "result_df = pd.DataFrame(results, columns=[\n",
    "    \"Feature_Type\", \"Model\", \"Dim\",\n",
    "    \"R2_mean\", \"R2_std\", \"MAE_mean\", \"MAE_std\"\n",
    "])\n",
    "print(result_df)\n",
    "result_df.to_csv('results/ADD/19_science_7-3_split_30_pca_unimol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature_Type Model  Dim   R2_mean    R2_std   MAE_mean   MAE_std\n",
      "0  OneHot_SMILES    RF   55  0.675637  0.111148  29.943669  3.762986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# conjugate\n",
    "results = []\n",
    "#运行对比 只使用随机森林模型\n",
    "# load data without pca\n",
    "X_onehot = OHE_pep\n",
    "X_fp = FP_pep.fillna(0)\n",
    "X_desc = FP_pep\n",
    "X_mord = Mord_pep\n",
    "X_unimol = UniMol_pep\n",
    "\n",
    "y = df_pep['Reaction I eesyn (%)'].values\n",
    "\n",
    "# 1 test on 19 science data\n",
    "for X, name, dim in [\n",
    "    (X_onehot, \"OneHot_SMILES\", X_onehot.shape[1]),\n",
    "    # (X_fp, \"Fingerprint\", X_fp.shape[1]),\n",
    "    # (clean_rdkit_features(X_desc), \"RDKit_Descriptors\", X_desc.shape[1]),\n",
    "    # (X_mord, \"Mordred\", X_mord.shape[1]),\n",
    "    # (X_unimol,'Unimol',X_unimol.shape[1])\n",
    "]:\n",
    "    for model in [\"RF\"]:\n",
    "        result = evaluate_model(X, y, model_type=model, n_runs=30)\n",
    "        results.append([name, model, dim,\n",
    "                        result['R2_mean'], result['R2_std'],\n",
    "                        result['MAE_mean'], result['MAE_std']])\n",
    "\n",
    "result_df = pd.DataFrame(results, columns=[\n",
    "    \"Feature_Type\", \"Model\", \"Dim\",\n",
    "    \"R2_mean\", \"R2_std\", \"MAE_mean\", \"MAE_std\"\n",
    "])\n",
    "print(result_df)\n",
    "result_df.to_csv('results/ADD/conjugate_7-3_split_30_oh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:49<00:00,  5.65s/it]\n",
      "100%|██████████| 30/30 [08:52<00:00, 17.75s/it]\n",
      "100%|██████████| 30/30 [03:39<00:00,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature_Type Model  Dim   R2_mean    R2_std  MAE_mean   MAE_std  \\\n",
      "0        Fingerprint    RF  100  0.862435  0.011537  6.775841  0.187797   \n",
      "1  RDKit_Descriptors    RF  100  0.855471  0.009001  7.453152  0.169071   \n",
      "2            Mordred    RF  100  0.869478  0.010302  6.591533  0.143120   \n",
      "\n",
      "   Time_mean  Time_std  \n",
      "0   5.642702  0.122901  \n",
      "1  17.749761  0.559831  \n",
      "2   7.317358  0.207988  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# X_onehot = OHE_18\n",
    "# X_fp = FP_18\n",
    "# X_desc = RDKit_18\n",
    "# X_mord = Mord_18\n",
    "y = df_18['Output'].values\n",
    "\n",
    "# load data with pca\n",
    "pca = PCA(n_components=100)\n",
    "X_fp = pca.fit_transform(FP_18.fillna(0))\n",
    "X_desc = pca.fit_transform(RDKit_18)\n",
    "X_mord = pca.fit_transform(Mord_18)\n",
    "\n",
    "# 1 test on 18 science data\n",
    "for X, name, dim in [\n",
    "    # (X_onehot, \"OneHot_SMILES\", X_onehot.shape[1]),\n",
    "    (X_fp, \"Fingerprint\", X_fp.shape[1]),\n",
    "    (clean_rdkit_features(X_desc), \"RDKit_Descriptors\", X_desc.shape[1]),\n",
    "    (X_mord, \"Mordred\", X_mord.shape[1]),\n",
    "]:\n",
    "    for model in [ \"RF\"]:\n",
    "        result = evaluate_model(X, y, model_type=model, n_runs=30)\n",
    "        results.append([name, model, dim,\n",
    "                        result['R2_mean'], result['R2_std'],\n",
    "                        result['MAE_mean'], result['MAE_std'],\n",
    "                        result['Time_mean'], result['Time_std']])\n",
    "\n",
    "result_df = pd.DataFrame(results, columns=[\n",
    "    \"Feature_Type\", \"Model\", \"Dim\",\n",
    "    \"R2_mean\", \"R2_std\", \"MAE_mean\", \"MAE_std\",\n",
    "    \"Time_mean\", \"Time_std\"\n",
    "])\n",
    "print(result_df)\n",
    "result_df.to_csv('results/ADD/18_science_RF_300_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:32<00:00,  1.09s/it]\n",
      "100%|██████████| 30/30 [07:18<00:00, 14.61s/it]\n",
      "100%|██████████| 30/30 [02:52<00:00,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature_Type Model  Dim   R2_mean    R2_std  MAE_mean   MAE_std\n",
      "0        Fingerprint    RF  100  0.843082  0.008093  0.076762  0.001839\n",
      "1  RDKit_Descriptors    RF  100  0.747930  0.010618  0.104555  0.002450\n",
      "2            Mordred    RF  100  0.799522  0.009492  0.091249  0.002502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# X_onehot = OHE_sm\n",
    "# X_fp = FP_sm\n",
    "# X_desc = RDkit_sm\n",
    "# X_mord = Mord_sm\n",
    "y = df_sm['Output'].values\n",
    "\n",
    "# load data with pca\n",
    "pca = PCA(n_components=100)\n",
    "X_fp = pca.fit_transform(FP_sm.fillna(0))\n",
    "X_desc = pca.fit_transform(RDkit_sm.fillna(0))\n",
    "X_mord = pca.fit_transform(Mord_sm)\n",
    "\n",
    "# 1 test on suzuki  data\n",
    "for X, name, dim in [\n",
    "    # (X_onehot, \"OneHot_SMILES\", X_onehot.shape[1]),\n",
    "    (X_fp, \"Fingerprint\", X_fp.shape[1]),\n",
    "    (clean_rdkit_features(X_desc), \"RDKit_Descriptors\", X_desc.shape[1]),\n",
    "    (X_mord, \"Mordred\", X_mord.shape[1]),\n",
    "    # (X_unimol, \"Uni-Mol\", X_unimol.shape[1])\n",
    "]:\n",
    "    for model in [ \"RF\"]:\n",
    "        result = evaluate_model(X, y, model_type=model, n_runs=30)\n",
    "        results.append([name, model, dim,\n",
    "                        result['R2_mean'], result['R2_std'],\n",
    "                        result['MAE_mean'], result['MAE_std']])\n",
    "\n",
    "result_df = pd.DataFrame(results, columns=[\n",
    "    \"Feature_Type\", \"Model\", \"Dim\",\n",
    "    \"R2_mean\", \"R2_std\", \"MAE_mean\", \"MAE_std\"\n",
    "])\n",
    "print(result_df)\n",
    "result_df.to_csv('results/ADD/suzuki_RF_300_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unimol_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
